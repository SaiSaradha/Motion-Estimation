{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Motion estimation is a very interesting exercise and this topic has numerous applications, some of them include object tracking, video compression, etc., In this exercise we explore some of the fundamental and core algorithms behind the motion estimation technique. There are different types of algorithms for ME and in this first exercise we focus on 'Block matching'. Here, we compare the consecutive frames block by block and try to find the best matching position for the block in the current frame based on some metric. The most commonly used metrics are SSD, SAD, Correlation, NCC, etc., In the demo, they showed us the correlation. I have explored the following here: \n",
    "1. Normalized Cross Correlation has been used as the metric\n",
    "2. Gaussian Pyramid approach to speed up and improve the results\n",
    "3. Phase Correlation implementation\n",
    "\n",
    "I will discuss each of the implementations and results below. Though the results are not satisfying, the approach is in the right direction, with few more fixes it should work for simple cases. We also discuss the fall downs of these correlation based algorithms and move on to show good results followed by tracking in exercise 2.\n",
    "\n",
    "I have implemented the entire code from scratch avoiding the use of built-in or library functions.\n",
    "\n",
    "Note: I implemented both exercises in the same python class. Hence, the same code is in both exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from scipy import ndimage\n",
    "import scipy\n",
    "import time\n",
    "from math import sqrt, cos, pi\n",
    "import matplotlib \n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from scipy.signal import correlate2d\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Motion_est:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.track_len = 10\n",
    "        self.detect_interval = 5\n",
    "        self.tracks = []\n",
    "        self.tracks_poly = []\n",
    "        self.frame_idx = 0\n",
    "\n",
    "    def plotflow(self, I, X, Y, U, V, scale=1, threshold=-1):\n",
    "        fig, ax = plt.subplots(figsize=(10, 10), dpi=80)\n",
    "        if threshold > 0:\n",
    "            mask = np.abs(U + 1j*V) > threshold\n",
    "            X = X[mask]\n",
    "            Y = Y[mask]\n",
    "            U = U[mask]\n",
    "            V = V[mask]\n",
    "            \n",
    "        ax.imshow(I, cmap='gray')\n",
    "        ax.quiver(X, Y, U*scale, V*scale, color='red', angles='xy', scale_units='xy', scale=1)\n",
    "        ax.set_aspect('equal')\n",
    "        plt.show()\n",
    "        return   \n",
    "    \n",
    "    def cor_f(self, choice, path):\n",
    "        Img1, Img2 = self.get_seq(choice, path)\n",
    "        # change above to run through all consecutive frames also\n",
    "\n",
    "        # now compute the image pyramid\n",
    "        pyramid_imgs, num_levels = self.pyramid_gaussian(Img2)\n",
    "        total_rows = 0\n",
    "        total_cols = 0\n",
    "        for i in range(int(num_levels)):\n",
    "            r, c, dd = pyramid_imgs[i].shape\n",
    "            total_rows += r\n",
    "            total_cols += c\n",
    "        # display the pyramid\n",
    "        pyramid_stack = np.zeros((total_rows, total_cols, dd), dtype = np.uint16)\n",
    "        i_row = 0\n",
    "        for i in range(int(num_levels)):\n",
    "            r, c, d = pyramid_imgs[i].shape\n",
    "            if i==0:\n",
    "                pyramid_stack[:r,:c,:d] = np.array(pyramid_imgs[i]).astype(np.uint16)\n",
    "                fr=r\n",
    "                fc=c\n",
    "                continue\n",
    "            pyramid_stack[i_row: i_row+r, fc:fc+c,:d] = np.array(pyramid_imgs[i]).astype(np.uint16)\n",
    "            fc+= c\n",
    "        cv2.imshow('ImagePyramid', pyramid_stack)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "        # now let's start working on block matching by correlation for motion estimation\n",
    "        ref_im = cv2.cvtColor(Img1, cv2.COLOR_BGR2GRAY)\n",
    "        h,w = ref_im.shape\n",
    "        hstart, hend,wstart,wend = 0,0,0,0\n",
    "        ws = 7 #match subblocks of size 7 x 7\n",
    "        x=np.arange(0, w, ws)\n",
    "        y=np.arange(0, h, ws)\n",
    "        gridX, gridY = np.meshgrid(x,y)\n",
    "        #print(gridX,gridY)\n",
    "        H, W = gridX.shape # the height and width of output \n",
    "        U = np.zeros((H, W))\n",
    "        V = np.zeros((H, W))\n",
    "        for i in range(H):\n",
    "            if hend+ws > h:\n",
    "                hstart = h-ws\n",
    "                hend = h\n",
    "            else:\n",
    "                hstart = hend\n",
    "                hend += ws\n",
    "            for j in range(W):\n",
    "                if wend+ws > w:\n",
    "                    wstart = w-ws\n",
    "                    wend =w\n",
    "                else:\n",
    "                    wstart = wend\n",
    "                    wend += ws\n",
    "                sub_block = ref_im[hstart:hend, wstart:wend]\n",
    "                ind={\n",
    "                    'h':h,\n",
    "                    'w':w,\n",
    "                    'hstart':hstart,\n",
    "                    'wstart':wstart,\n",
    "                    'ws':ws,\n",
    "                    }\n",
    "                u,v = self.ncc_calc(int(num_levels), pyramid_imgs, ind, sub_block)\n",
    "                U[i,j]=u\n",
    "                V[i,j]=v\n",
    "        # now call the routine to plot the motion vector:\n",
    "        self.plotflow(ref_im, gridX, gridY, U, V, 1, 0.3)\n",
    "        plt.hist(U.flatten())\n",
    "        plt.hist(V.flatten())\n",
    "        return\n",
    "\n",
    "    def ncc_calc(self, num_levels, pyramid_imgs, ind, sub_block):\n",
    "        r=2\n",
    "        c=2\n",
    "        ws = ind['ws']\n",
    "        for l in range(num_levels):\n",
    "            #print('level ', l)\n",
    "            coarse_im = cv2.cvtColor(pyramid_imgs[(num_levels-1)-l], cv2.COLOR_BGR2GRAY)\n",
    "            if l > 0:\n",
    "                i_new = max((i-1)*(r-1)+i,0)\n",
    "                j_new = max((j-1)*(c-1)+j,0)\n",
    "                #print(i_new, j_new)\n",
    "                rstart = max(i_new-ws,0)\n",
    "                rend = min(i_new+ws,ind['h'])\n",
    "                cstart = max(j_new-ws,0)\n",
    "                cend = min(j_new+ws,ind['w'])\n",
    "                coarse_im = coarse_im[rstart:rend, cstart:cend]\n",
    "            block_norm = sub_block - np.mean(sub_block)\n",
    "            block_norm /= (np.sum(block_norm**2))**0.5\n",
    "            coarse_norm = coarse_im - np.mean(coarse_im)\n",
    "            coarse_norm /= (np.sum(coarse_norm**2)**0.5)\n",
    "            #print(coarse_norm.shape)\n",
    "            ncc_output = correlate2d(coarse_norm, block_norm, 'same')\n",
    "            i, j = np.unravel_index(ncc_output.argmax(),ncc_output.shape)\n",
    "            # motion vector estimation\n",
    "            if l==num_levels-1:\n",
    "                #u = j_new - ind['h'] - ind['hstart'] + j\n",
    "                #v = i_new - ind['w'] - ind['wstart'] + i\n",
    "                #u = cstart - ind['wstart'] + j\n",
    "                #v = rstart - ind['hstart'] + i\n",
    "                u = cstart + j\n",
    "                v = rstart + i\n",
    "        return u,v\n",
    "\n",
    "    def poc_f(self, choice, path):\n",
    "        Img1, Img2 = self.get_seq(choice, path)\n",
    "        ref_im = cv2.cvtColor(Img1, cv2.COLOR_BGR2GRAY)\n",
    "        cur_im = cv2.cvtColor(Img2, cv2.COLOR_BGR2GRAY)\n",
    "        h,w = ref_im.shape\n",
    "        hstart, hend,wstart,wend = 0,0,0,0\n",
    "        bs = 16\n",
    "        x=np.arange(0, w, bs)\n",
    "        y=np.arange(0, h, bs)\n",
    "        gridX, gridY = np.meshgrid(x,y)\n",
    "        H, W = gridX.shape # the height and width of output \n",
    "        U = np.zeros((H, W))\n",
    "        V = np.zeros((H, W))\n",
    "        for i in range(H):\n",
    "            if hend+bs > h:\n",
    "                hstart = h-bs\n",
    "                hend = h\n",
    "                hsc = h-2*bs\n",
    "                hec = h\n",
    "            else:\n",
    "                hstart = hend\n",
    "                hend += bs\n",
    "                hsc = hstart-bs\n",
    "                hec = hend+bs\n",
    "            if hstart-bs < 0:\n",
    "                hsc = 0\n",
    "                hec = hend + 2*bs                \n",
    "            for j in range(W):\n",
    "                if wend+bs > w:\n",
    "                    wstart = w-bs\n",
    "                    wend =w\n",
    "                    wsc = w - 2*bs\n",
    "                    wec = w\n",
    "                else:\n",
    "                    wstart = wend\n",
    "                    wend += bs\n",
    "                    wsc = wstart - bs\n",
    "                    wec = wend+bs\n",
    "                if wstart-bs<0:\n",
    "                    wsc = 0\n",
    "                    wec = wend + 2*bs\n",
    "                sub_block_r = ref_im[hstart:hend, wstart:wend]\n",
    "                #sub_block_c = cur_im[hstart:hend, wstart:wend]\n",
    "                sub_block_c = cur_im[hsc:hec, wsc:wec]\n",
    "                u,v = self.poc_calc(sub_block_r, sub_block_c, hsc, wsc)\n",
    "                U[i,j]=u\n",
    "                V[i,j]=v\n",
    "        # now call the routine to plot the motion vector:\n",
    "        self.plotflow(ref_im, gridX, gridY, U, V, 1, 0.3)\n",
    "        plt.hist(U.flatten())\n",
    "        plt.hist(V.flatten())\n",
    "        return\n",
    "\n",
    "    def poc_calc(self, rim, cim, hstart, wstart):\n",
    "        h, w = rim.shape\n",
    "        hc, wc = cim.shape\n",
    "        bs = 16\n",
    "        hsc, hec, wsc, wec = 0, 0, 0, 0\n",
    "        hc_check, wc_check = True, True\n",
    "        temp_max = []\n",
    "        u_temp,v_temp = [], []\n",
    "        for i in range(hc):\n",
    "            if hc_check == False:\n",
    "                continue\n",
    "            if hsc+bs > hc:\n",
    "                hsc = hc-bs\n",
    "                hec = hc\n",
    "                hc_check = False\n",
    "            else:\n",
    "                hsc += 1\n",
    "                hec = hsc + bs\n",
    "            for j in range(wc):\n",
    "                if wc_check == False:\n",
    "                    continue\n",
    "                if wec+bs > wc:\n",
    "                    wsc = wc-bs\n",
    "                    wec = wc\n",
    "                    wc_check = False\n",
    "                else:\n",
    "                    wsc += 1\n",
    "                    wec = wsc + bs\n",
    "                #print(cim.shape)\n",
    "                cim_sub = cim[hsc:hec, wsc:wec]\n",
    "                #print(hsc, hec, wsc, wec)\n",
    "                #print(cim_sub.shape)\n",
    "                hanning = [np.hanning(h), np.hanning(w)]\n",
    "                window = hanning[1].reshape(hanning[1].shape[0],1)*hanning[0]\n",
    "                #print(window.shape)\n",
    "                rim1 = np.float64(rim)*window\n",
    "                cim1 = np.float64(cim_sub)*window\n",
    "                fft_im1 = np.fft.fft2(rim1)\n",
    "                fft_im2 = np.fft.fft2(cim1)\n",
    "                cross_power = fft_im1 * np.ma.conjugate(fft_im2)\n",
    "                #cross_power = fft_im1 * np.conjugate(fft_im2)/np.absolute(fft_im1*np.conjugate(fft_im2))\n",
    "                cross_power/= np.absolute(cross_power)\n",
    "                ncc_output = np.real(np.fft.ifft2(cross_power))\n",
    "                i, j = np.unravel_index(ncc_output.argmax(),ncc_output.shape)\n",
    "                u = wsc+j\n",
    "                v = hsc+i\n",
    "                temp_max.append(ncc_output[i,j])\n",
    "                u_temp.append(u)\n",
    "                v_temp.append(v)\n",
    "        max_ind = np.argmax(temp_max)\n",
    "        u = u_temp[max_ind]\n",
    "        v = v_temp[max_ind]\n",
    "        return u, v\n",
    "\n",
    "    def gradient_xyt(self, I1, I2, x, y):\n",
    "        h, w = I1.shape\n",
    "        x = int(x)\n",
    "        y = int(y)\n",
    "        \n",
    "        Ix = (x>0 and x< (w-1) and y>=0 and y<h ) and (I1[y, x+1] - I1[y, x-1])/2 or 0\n",
    "        Iy = (x>=0 and x<w and y>0 and y< (h-1) ) and (I1[y+1, x] - I1[y-1, x])/2 or 0\n",
    "        It = (x>=0 and x<w and y>=0 and y<h) and I2[y,x] - I1[y,x] or 0\n",
    "        return (Ix, Iy, It)\n",
    "\n",
    "    def getAb(self, I1, I2, x, y, n):\n",
    "        A = np.zeros((n*n, 2))\n",
    "        b = np.zeros(n*n)\n",
    "        \n",
    "        # compute the relative positions of pixels in a window\n",
    "        offset = np.arange(0, n) - np.floor(n/2); \n",
    "        dx, dy = np.meshgrid(offset, offset);\n",
    "        dx = dx.reshape(n*n, 1);\n",
    "        dy = dy.reshape(n*n, 1);\n",
    "        \n",
    "        # compute the elements of A and b\n",
    "        for i in range(0, n*n):\n",
    "            Ix, Iy, It = self.gradient_xyt(I1, I2, x+dx[i], y+dy[i])\n",
    "            A[i, 0] = Ix \n",
    "            A[i, 1] = Iy\n",
    "            b[i] = -It\n",
    "            \n",
    "        return (A, b)\n",
    "\n",
    "    ##  flow->motion\n",
    "    def estimate_flow_at_xy(self, I1, I2, x, y, n):\n",
    "        A, b = self.getAb(I1, I2, x, y, n)\n",
    "     \n",
    "        # least square \n",
    "        # https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.linalg.lstsq.html  \n",
    "        result = np.linalg.lstsq(np.matmul(A.T, A), np.matmul(A.T, b))\n",
    "        # result = np.linalg.lstsq(A, b)\n",
    "        v = result[0]\n",
    "        return v\n",
    "\n",
    "    def estimate_flow(self, I1, I2, gridX, gridY, n):\n",
    "        H, W = gridX.shape # the height and width of output \n",
    "        U = np.zeros((H, W))\n",
    "        V = np.zeros((H, W))\n",
    "        \n",
    "        # iterate over the grid\n",
    "        for i in range(0, H):\n",
    "            for j in range(0, W):\n",
    "                v =  self.estimate_flow_at_xy(I1, I2,gridX[i, j], gridY[i, j], n)\n",
    "                U[i, j] = v[0]\n",
    "                V[i, j] = v[1]\n",
    "        return (U, V)\n",
    "\n",
    "    def kl_f(self, choice, path):\n",
    "        Img1, Img2 = self.get_seq(choice, path)\n",
    "        #Img1 = cv2.cvtColor(Img1, cv2.COLOR_BGR2GRAY)\n",
    "        #Img2 = cv2.cvtColor(Img2, cv2.COLOR_BGR2GRAY)\n",
    "        Img1 = self.gaussian_blur(cv2.cvtColor(Img1, cv2.COLOR_BGR2GRAY))\n",
    "        Img2 = self.gaussian_blur(cv2.cvtColor(Img2, cv2.COLOR_BGR2GRAY))\n",
    "        H, W = Img1.shape\n",
    "        gridsz = 9\n",
    "        wsz  = 21\n",
    "        x = np.arange(0, W-gridsz, gridsz) + np.floor(gridsz/2);\n",
    "        y = np.arange(0, H-gridsz, gridsz) + np.floor(gridsz/2);\n",
    "        gridX, gridY = np.meshgrid(x,y);\n",
    "        U, V = self.estimate_flow(Img1, Img2, gridX, gridY, wsz)\n",
    "        self.plotflow(Img1, gridX, gridY, U, V, 1, 5)\n",
    "        return\n",
    "\n",
    "\n",
    "    def hs_f(self, choice, path):\n",
    "        Img1, Img2 = self.get_seq(choice, path)\n",
    "        Img1 = self.gaussian_blur(cv2.cvtColor(Img1, cv2.COLOR_BGR2GRAY)).astype(np.float)\n",
    "        Img2 = self.gaussian_blur(cv2.cvtColor(Img2, cv2.COLOR_BGR2GRAY)).astype(np.float)\n",
    "        num_iter = 100\n",
    "        reg_const = 1\n",
    "        h, w = Img1.shape\n",
    "        U = np.zeros((h,w))\n",
    "        V = np.zeros((h,w))\n",
    "        \n",
    "        Ix, Iy, It = self.gradient_hs(Img1, Img2)\n",
    "        fs = np.array([[1/12,1/6,1/12],[1/6,0,1/6],[1/12,1/6,1/12]], dtype = float)\n",
    "        for i in range(num_iter):\n",
    "            u_bar = cv2.filter2D(U, -1, fs)\n",
    "            v_bar = cv2.filter2D(V, -1, fs)\n",
    "            U = u_bar - Ix*((Ix*u_bar + Iy*v_bar + It)/(reg_const**2+Ix**2+Iy**2))\n",
    "            V = v_bar - Iy*((Ix*u_bar + Iy*v_bar + It)/(reg_const**2+Ix**2+Iy**2))\n",
    "        ws = 5\n",
    "        x=np.arange(0, w, ws)\n",
    "        y=np.arange(0, h, ws)\n",
    "        gridX, gridY = np.meshgrid(x,y)\n",
    "        g_x_s, g_y_s = gridX.shape\n",
    "        U_plot = np.zeros((g_x_s, g_y_s))\n",
    "        V_plot = np.zeros((g_x_s, g_y_s))\n",
    "        jc, kc = 0, 0\n",
    "        for j in range(0, len(U), ws):\n",
    "            kc = 0\n",
    "            for k in range(0, len(V), ws):\n",
    "                U_plot[jc, kc] = U[j,k]\n",
    "                V_plot[jc, kc] = V[j,k]\n",
    "                kc += 1\n",
    "            jc+=1\n",
    "        self.plotflow(Img1, gridX, gridY, np.array(U_plot), np.array(V_plot), 1, 0.3) # for worm, set threshold to 5\n",
    "        return\n",
    "\n",
    "    def gradient_hs(self, Img1, Img2):\n",
    "        k_x = np.array([[-1/4, 1/4],[-1/4, 1/4]], dtype = float)\n",
    "        k_y = np.array([[-1/4, -1/4],[1/4, 1/4]], dtype = float)\n",
    "        k_t = np.array([[1/4, 1/4],[1/4, 1/4]], dtype = float)\n",
    "        #Ix = cv2.filter2D(Img1,-1,k_x)+cv2.filter2D(Img2,-1,k_x)\n",
    "        #Iy = cv2.filter2D(Img1,-1,k_y)+cv2.filter2D(Img2,-1,k_y)\n",
    "        #It = cv2.filter2D(Img1,-1,k_t)-cv2.filter2D(Img2,-1,k_t)\n",
    "        Ix = signal.convolve2d(Img1, k_x, 'same')+signal.convolve2d(Img2,k_x, 'same')\n",
    "        Iy = signal.convolve2d(Img1, k_y, 'same')+signal.convolve2d(Img2,k_y, 'same')\n",
    "        It = signal.convolve2d(Img1, k_t, 'same')-signal.convolve2d(Img2,k_t, 'same')\n",
    "        return Ix, Iy, It\n",
    "\n",
    "    def klt_track(self, choice, path):\n",
    "        img_folder, fname_ip = self.get_seq(choice, path)\n",
    "        vcapt = cv2.VideoCapture(img_folder + fname_ip)\n",
    "        frame_width = int(vcapt.get(3))\n",
    "        frame_height = int(vcapt.get(4))\n",
    "        out = cv2.VideoWriter('outpy.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width,frame_height))\n",
    "        if (vcapt.isOpened()== False):\n",
    "            print(\"Error opening video stream or file\")\n",
    "        while(vcapt.isOpened()):\n",
    "            ret, frame = vcapt.read()\n",
    "            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            vis = frame.copy()\n",
    "            print('Frame: ', self.frame_idx)\n",
    "            if len(self.tracks) > 0:\n",
    "                img0, img1 = self.prev_gray, frame_gray\n",
    "                p0 = np.float32([tr[-1] for tr in self.tracks]).reshape(-1, 1, 2)\n",
    "                p1 = self.hs_track_point(img0, img1, p0)\n",
    "                #print('returned p1')\n",
    "                '''p0r = self.hs_track_point(img1, img0, p1)\n",
    "                print('returned p0r')\n",
    "                d = abs(p0-p0r).reshape(-1, 2).max(-1)\n",
    "                print(d)\n",
    "                good = d < 1'''\n",
    "                new_tracks = []\n",
    "                new_tracks_poly = []\n",
    "                '''for tr, (x, y), good_flag in zip(self.tracks, p1.reshape(-1, 2), good):\n",
    "                    if not good_flag:\n",
    "                        continue'''\n",
    "                for tr, tr_poly, (x, y) in zip(self.tracks, self.tracks_poly, p1.reshape(-1, 2)):\n",
    "                    tr.append((x, y))\n",
    "                    tr_poly.append((y,x))\n",
    "                    if len(tr) > self.track_len:\n",
    "                        del tr[0]\n",
    "                        del tr_poly[0]\n",
    "                    new_tracks.append(tr)\n",
    "                    new_tracks_poly.append(tr_poly)\n",
    "                    cv2.circle(vis, (int(y), int(x)), 2, (0, 255, 0), -1)\n",
    "                self.tracks = new_tracks\n",
    "                self.tracks_poly = new_tracks_poly\n",
    "                cv2.polylines(vis, [np.int32(tr) for tr in self.tracks_poly], False, (0, 255, 0))\n",
    "                #cv2.polylines(vis, [np.int32(tr) for tr in self.tracks], False, (0, 255, 0))\n",
    "                #draw_str(vis, (20, 20), 'track count: %d' % len(self.tracks))\n",
    "                \n",
    "            if self.frame_idx % self.detect_interval == 0:\n",
    "                p = cv2.cornerHarris(frame_gray,2,3,0.04)\n",
    "                #vis[p>0.01*p.max()]=[0,255,0]\n",
    "                pf = np.where(p>0.01*p.max())\n",
    "                pf_list = list(zip(*pf))\n",
    "                if pf_list is not None:\n",
    "                    #for x, y in np.float32(pf).reshape(-1, 2):\n",
    "                        #print(x,y)\n",
    "                    for x,y in pf_list:\n",
    "                        self.tracks.append([(x, y)])\n",
    "                        self.tracks_poly.append([(y,x)])\n",
    "                        # to display the corner points\n",
    "                        #cv2.imshow('vis', vis)\n",
    "\n",
    "            '''if self.frame_idx % self.detect_interval == 0:\n",
    "                mask = np.zeros_like(frame_gray)\n",
    "                mask[:] = 255\n",
    "                for x, y in [np.int32(tr[-1]) for tr in self.tracks]:\n",
    "                    cv2.circle(mask, (x, y), 5, 0, -1)\n",
    "                p = cv2.goodFeaturesToTrack(frame_gray, mask = mask, **feature_params)\n",
    "                if p is not None:\n",
    "                    for x, y in np.float32(p).reshape(-1, 2):\n",
    "                        self.tracks.append([(x, y)])'''\n",
    "            \n",
    "            self.prev_gray = frame_gray\n",
    "            cv2.imshow('lk_track', vis)\n",
    "            out.write(vis)\n",
    "            self.frame_idx += 1\n",
    "\n",
    "            ch = cv2.waitKey(1)\n",
    "            if ch == 27:\n",
    "                break\n",
    "        return\n",
    "\n",
    "    def hs_track_point(self, Img1, Img2, p):\n",
    "        Img1 = self.gaussian_blur(Img1).astype(np.float)\n",
    "        Img2 = self.gaussian_blur(Img2).astype(np.float)\n",
    "        num_iter = 10\n",
    "        reg_const = 1\n",
    "        h, w = Img1.shape\n",
    "        U = np.zeros((h,w))\n",
    "        V = np.zeros((h,w))\n",
    "        \n",
    "        Ix, Iy, It = self.gradient_hs(Img1, Img2)\n",
    "        fs = np.array([[1/12,1/6,1/12],[1/6,0,1/6],[1/12,1/6,1/12]], dtype = float)\n",
    "        for i in range(num_iter):\n",
    "            u_bar = cv2.filter2D(U, -1, fs)\n",
    "            v_bar = cv2.filter2D(V, -1, fs)\n",
    "            U = u_bar - Ix*((Ix*u_bar + Iy*v_bar + It)/(reg_const**2+Ix**2+Iy**2))\n",
    "            V = v_bar - Iy*((Ix*u_bar + Iy*v_bar + It)/(reg_const**2+Ix**2+Iy**2))\n",
    "        UV = []\n",
    "        jc = 0\n",
    "        for pt in range(len(p)):\n",
    "            xpt, ypt = p[pt][0]\n",
    "            xpt = min(xpt, h-1)\n",
    "            ypt = min(ypt, w-1)\n",
    "            UV.append([(int(xpt)+V[int(xpt), int(ypt)],int(ypt)+U[int(xpt),int(ypt)])])\n",
    "            #UV.append([(int(ypt)+U[int(xpt),int(ypt)],int(xpt)+V[int(xpt), int(ypt)])])\n",
    "        return np.array(UV)\n",
    "    \n",
    "    def kal_track(self, choice, path):\n",
    "        Img1, Img2 = self.get_seq(choice, path)\n",
    "        pass\n",
    "\n",
    "    def normalize_fn(self, choice, path):\n",
    "        pass\n",
    "\n",
    "    def gaussian_blur(self, img):\n",
    "        fs = 3\n",
    "        Img_final = cv2.GaussianBlur(img, (fs,fs),0)\n",
    "        Img2 = Img_final.astype(np.uint8)\n",
    "        return Img_final\n",
    "\n",
    "    def remove_r_c(self, img):\n",
    "        return img[::2,::2,:]\n",
    "\n",
    "    def pyramid_gaussian(self, img):\n",
    "        num_levels = input('Enter the number of levels in the pyramid: ')\n",
    "        pyramid_img = [img]\n",
    "        for l in range(int(num_levels)-1):\n",
    "            img = self.gaussian_blur(img)\n",
    "            img = self.remove_r_c(img)\n",
    "            print(img.shape)\n",
    "            pyramid_img.append(img)\n",
    "        return pyramid_img, num_levels\n",
    "\n",
    "    def plot_hist(self):\n",
    "        pass\n",
    "    \n",
    "    def plot_motion(self):\n",
    "        pass\n",
    "\n",
    "    def video_to_frames(self, filename, path):\n",
    "        directory = os.fsencode(path)\n",
    "        vcapt = cv2.VideoCapture(path + filename)\n",
    "        captured, frame = vcapt.read()\n",
    "        count = 0\n",
    "        captured = True\n",
    "        while captured:\n",
    "            cv2.imwrite(os.path.join(path,\"frame%d.jpg\" % count), frame)\n",
    "            success,frame = vcapt.read()\n",
    "            count += 1\n",
    "        return\n",
    "    \n",
    "    def get_seq(self, choice, img_folder):\n",
    "        directory = os.fsencode(img_folder)\n",
    "        vid = input('Convert video to seq images ? enter y or n: ')\n",
    "        if vid == 'y':\n",
    "            fname_ip = input('Enter the name of the video file: ')\n",
    "            for file in os.listdir(img_folder):\n",
    "                filename = os.fsdecode(file)\n",
    "                if not (fname_ip == filename):\n",
    "                    continue\n",
    "                self.video_to_frames(filename,img_folder)\n",
    "                break\n",
    "        # now get the two sequences to plot motion vector\n",
    "        if choice == 'klt_track' or choice == 'kal_track':\n",
    "                if vid == 'n':\n",
    "                    fname_ip = input('Enter the name of the video file: ')\n",
    "                print('Showing input video')\n",
    "                vcapt = cv2.VideoCapture(img_folder + fname_ip)\n",
    "                if (vcapt.isOpened()== False):\n",
    "                    print(\"Error opening video stream or file\")\n",
    "                while(vcapt.isOpened()):\n",
    "                    ret, frame = vcapt.read()\n",
    "                    if ret == True:\n",
    "                        cv2.imshow('Frame',frame)\n",
    "                        if cv2.waitKey(25) & 0xFF == ord('e'):\n",
    "                            break\n",
    "                    else:\n",
    "                        break\n",
    "                vcapt.release()\n",
    "                return img_folder, fname_ip\n",
    "        else:\n",
    "                ip1 = input('Enter the name of the reference image: ')\n",
    "                ip2 = input('Enter the name of the current image: ')\n",
    "                if os.fsencode(ip1) not in os.listdir(directory) or os.fsencode(ip2) not in os.listdir(directory):\n",
    "                    print('wrong input file name')\n",
    "                    return\n",
    "                Img1 = self.read_image(img_folder, ip1)\n",
    "                Img2 = self.read_image(img_folder, ip2)\n",
    "                if Img1 is None or Img2 is None:\n",
    "                    print('Input image is None, returning')\n",
    "                    return\n",
    "                cv2.namedWindow('Reference Image')\n",
    "                cv2.imshow('Reference Image', Img1)\n",
    "                cv2.namedWindow('Current Image')\n",
    "                cv2.imshow('Current Image', Img2)\n",
    "                cv2.waitKey(0)\n",
    "                return Img1, Img2\n",
    "            \n",
    "    def read_image(self, directory, filename):\n",
    "        #if filename.startswith(\"f\") and (filename.endswith(\".jpg\") or filename.endswith(\".bmp\") or filename.endswith(\".png\") or filename.endswith(\".gif\")):\n",
    "        if (filename.endswith(\".jpg\") or filename.endswith(\".bmp\") or filename.endswith(\".png\") or filename.endswith(\".gif\")):\n",
    "            print(filename)\n",
    "            img = cv2.imread(directory + filename,-1)\n",
    "            if img is None:\n",
    "                print('Invalid image:' + filename)\n",
    "                return None\n",
    "            return img\n",
    "\n",
    "    def main(self, choice, path):\n",
    "        options = {'cor_f':self.cor_f,\n",
    "                   'poc_f':self.poc_f,\n",
    "                   'kl_f': self.kl_f,\n",
    "                   'hs_f': self.hs_f,\n",
    "                   'klt_track':self.klt_track,\n",
    "                   'kal_track':self.kal_track,\n",
    "            }\n",
    "        options[choice](choice, path)\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # creating an instance of the motion estimation class\n",
    "    me_class = Motion_est()\n",
    "\n",
    "    # Call to the main function\n",
    "    tic = time.time()\n",
    "    print('Choices are : \\n 1. Correlation(cor_f) \\n 2. Phase Correlation (poc_f) \\n 3. Lucas Kanade (kl_f) \\n 4. Horn&Schunck (hs_f) \\n 5. KLT tracker (klt_track) and \\n 6. Kalman+Hanning(kal_track)')\n",
    "    choice_v = input(\"Enter the choice: \")\n",
    "    path = input(\"Enter the folder to the seq or video: \")\n",
    "    # for path enter ..\\\\input\\\\\n",
    "    me_class.main(choice_v, path)\n",
    "    toc = time.time() - tic\n",
    "    print(\"Running time: \" + str(toc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized Cross Correlation:\n",
    "\n",
    "NCC is a simpler method but is considerably effective compared to other methods such as SAD and SSD. The range of the correlation value is between -1 and +1 and this is because the correlation computation is equivalent to finding the dot product between two unit vectors,. Since it is normalized, NCC is less sensitive to the luminance variation.\n",
    "\n",
    "The computation for the three metrics (SSD, SAD, NCC) are as follows (here f and g are the image blocks in current and reference frame respectively) :\n",
    "\n",
    "$$\\mathrm{SSD}(f,g) : \\sum_{[i,j]\\in R} \\left(f(i,j)-g(i,j)\\right)^{2}$$\n",
    "$$\\mathrm{SAD}(f,g) : \\sum_{[i,j]\\in R} \\left|f(i,j)-g(i,j)\\right|$$\n",
    "$$\\mathrm{NCC}(f,g) : \\sum_{[i,j] \\in R}\\hat{f}(i,j)\\hat{g}(i,j) = \\sum_{[i,j] \\in R} \\Bigg(\\frac{f-\\bar{f}}{\\sqrt{\\sum(f-\\bar{f})^{2}}}\\Bigg)\\Bigg(\\frac{g-\\bar{g}}{\\sqrt{\\sum(g-\\bar{g})^{2}}}\\Bigg)$$\n",
    "\n",
    "Here I have used the NCC as the metric to find the best match of the motion and have also tried a gaussian pyramid based implementation.\n",
    "\n",
    "Gaussian Pyramid is where the image is subsampled after smoothing the image with a gaussian kernel. When the code is run, the user can first select what type of motion estimation algorithm they would like to run. Then there is a prompt to enter the current and reference (previous frame) image path. After this, the user has to enter the number of levels in an image pyramid (for the sphere, I chose L=4 and can vary depending on the image/sequence size). \n",
    "\n",
    "![Alt text](imgs/pyramid_text.png?raw=true \"pyramid_text\")\n",
    "\n",
    "The gaussian pyramid image for the sphere image with 4 levels looks like this:\n",
    "![Alt text](imgs/pyramid.png?raw=true \"pyramid\")\n",
    "\n",
    "1. At the coarsest level, the image is pretty small. So for every block in the reference image, exhaustive search (on entire coarse image) is done to find the maximum NCC value and that block is chosen to be the match for this block. This is repeated for every block. We now have a block match at the coarse current image level for every block in the reference image.\n",
    "2. Now, find the corresponding corresponding coordinate in the higher level using the following formula :\n",
    "i_match = (i-1)(r-1)+i\n",
    "j_match = (j-1)(c-1)+j\n",
    "where i, j are the coordinates of the reference block, r and c is the subsampling ratio (in this case, r=c=2).\n",
    "3. Now in the slightly finer level image, use a window of +/- ws (here ws = 7) pixels on each side and this becomes the search region. We find the best match here and then continue doing the same as in the above steps until we reach the original current image.\n",
    "\n",
    "![Alt text](imgs/corr_final_output.png?raw=true \"corr_final_output\")\n",
    "\n",
    "Above is the result by Pyramid based NCC for sphere sequence (sphere.1.png and sphere.3.png)\n",
    "As we can see from the result, it is not great. I guess this is mostly because there is rotational motion between the frames and correlation has no way of identifying that.\n",
    "\n",
    "Below is the output for Rubic and again this is not great but atleast at some points the motion has been estimated correctly.\n",
    "\n",
    "![Alt text](imgs/corr_final_rubic.png?raw=true \"corr_final_rubic\")\n",
    "\n",
    "Some improvements that I would like to try later on are - trying to threshold the intensity in the image (since there is some sensitivity to luminance), try different color spaces etc.,"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase Correlation :\n",
    "Consider two N1 x N2 images, f(m, n) and g(m, n) and their 2D DFTs (FFT) are denoted by F(K1, K2) and G(K1,K2) and as we know, the DFT includes both amplitude and phase components. \n",
    "Due to lack of time, instead of writing the equations myself I have pasted the image from source - http://www.aoki.ecei.tohoku.ac.jp/research/docs/444-250.pdf\n",
    "\n",
    "![Alt text](imgs/dft.PNG?raw=true \"dft\")\n",
    "\n",
    "We then find the NCC by computing the cross-power spectrum that is defined as,\n",
    "![Alt text](imgs/powerspectrum.PNG?raw=true \"powerspectrum\")\n",
    "\n",
    "The peak value is identified by finding the inverse FFT of this power spectrum and then taking argmax(). The overall flow is similar to the one below\n",
    "![Alt text](imgs/poc_steps.PNG?raw=true \"poc_steps\")\n",
    "\n",
    "In my implementation, the candidate search block in the current frame image is chosen by taking a window of bs pixels on each side around the block coordinates from the previous frame. I have also applied hanning window over the blocks. Then, an exhaustive search is done in this larger block to find the maximum correlation.\n",
    "\n",
    "As we can see from the results here, it is not great but has atleast improved better than the spatial domain correlation. I again believe strongly that the approach is in the right direction, however many papers have been proposed with different methods for better results (fitting based solution, etc.,)\n",
    "\n",
    "![Alt text](imgs/poc_rubic.png?raw=true \"poc_rubic\")\n",
    "\n",
    "from the rubic result we can see that in some places the motion vector has the right orientation but is not perfect.\n",
    "\n",
    "![Alt text](imgs/poc_seq_op.png?raw=true \"poc_seq_op\")\n",
    "![Alt text](imgs/poc_seq_op.png?raw=true \"poc_seq_op\")\n",
    "\n",
    "Here again is the output for the sequence frames. From the results, we can see the motion vector estimation is better but is not closer to the right one.\n",
    "I have got good results on the gradient based approaches and we discuss that in the next exercise. I have also done object tracking and that seemed to produce satisfactory initial results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
