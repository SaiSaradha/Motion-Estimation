{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, I have implemented the following :\n",
    "1. Horn and Schunck ME algorithm implementation and testing\n",
    "2. Slightly improved GCE by smoothing the images\n",
    "3. Track an earthworm's motion in a video with Harris corner points in a video\n",
    "All implementations have been done from scratch and for most part I have not used any of the built-in functions except in few places (eg. Harris corner point detection) which are not in the scope of the assignment.\n",
    "I also wanted to explore the kalman filter technique, but leaving that out as future exploration due to lack of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from scipy import ndimage\n",
    "import scipy\n",
    "import time\n",
    "from math import sqrt, cos, pi\n",
    "import matplotlib \n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from scipy.signal import correlate2d\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Motion_est:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.track_len = 10\n",
    "        self.detect_interval = 5\n",
    "        self.tracks = []\n",
    "        self.tracks_poly = []\n",
    "        self.frame_idx = 0\n",
    "\n",
    "    def plotflow(self, I, X, Y, U, V, scale=1, threshold=-1):\n",
    "        fig, ax = plt.subplots(figsize=(10, 10), dpi=80)\n",
    "        if threshold > 0:\n",
    "            mask = np.abs(U + 1j*V) > threshold\n",
    "            X = X[mask]\n",
    "            Y = Y[mask]\n",
    "            U = U[mask]\n",
    "            V = V[mask]\n",
    "            \n",
    "        ax.imshow(I, cmap='gray')\n",
    "        ax.quiver(X, Y, U*scale, V*scale, color='red', angles='xy', scale_units='xy', scale=1)\n",
    "        ax.set_aspect('equal')\n",
    "        plt.show()\n",
    "        return   \n",
    "    \n",
    "    def cor_f(self, choice, path):\n",
    "        Img1, Img2 = self.get_seq(choice, path)\n",
    "        # change above to run through all consecutive frames also\n",
    "\n",
    "        # now compute the image pyramid\n",
    "        pyramid_imgs, num_levels = self.pyramid_gaussian(Img2)\n",
    "        total_rows = 0\n",
    "        total_cols = 0\n",
    "        for i in range(int(num_levels)):\n",
    "            r, c, dd = pyramid_imgs[i].shape\n",
    "            total_rows += r\n",
    "            total_cols += c\n",
    "        # display the pyramid\n",
    "        pyramid_stack = np.zeros((total_rows, total_cols, dd), dtype = np.uint16)\n",
    "        i_row = 0\n",
    "        for i in range(int(num_levels)):\n",
    "            r, c, d = pyramid_imgs[i].shape\n",
    "            if i==0:\n",
    "                pyramid_stack[:r,:c,:d] = np.array(pyramid_imgs[i]).astype(np.uint16)\n",
    "                fr=r\n",
    "                fc=c\n",
    "                continue\n",
    "            pyramid_stack[i_row: i_row+r, fc:fc+c,:d] = np.array(pyramid_imgs[i]).astype(np.uint16)\n",
    "            fc+= c\n",
    "        cv2.imshow('ImagePyramid', pyramid_stack)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "        # now let's start working on block matching by correlation for motion estimation\n",
    "        ref_im = cv2.cvtColor(Img1, cv2.COLOR_BGR2GRAY)\n",
    "        h,w = ref_im.shape\n",
    "        hstart, hend,wstart,wend = 0,0,0,0\n",
    "        ws = 7 #match subblocks of size 7 x 7\n",
    "        x=np.arange(0, w, ws)\n",
    "        y=np.arange(0, h, ws)\n",
    "        gridX, gridY = np.meshgrid(x,y)\n",
    "        #print(gridX,gridY)\n",
    "        H, W = gridX.shape # the height and width of output \n",
    "        U = np.zeros((H, W))\n",
    "        V = np.zeros((H, W))\n",
    "        for i in range(H):\n",
    "            if hend+ws > h:\n",
    "                hstart = h-ws\n",
    "                hend = h\n",
    "            else:\n",
    "                hstart = hend\n",
    "                hend += ws\n",
    "            for j in range(W):\n",
    "                if wend+ws > w:\n",
    "                    wstart = w-ws\n",
    "                    wend =w\n",
    "                else:\n",
    "                    wstart = wend\n",
    "                    wend += ws\n",
    "                sub_block = ref_im[hstart:hend, wstart:wend]\n",
    "                ind={\n",
    "                    'h':h,\n",
    "                    'w':w,\n",
    "                    'hstart':hstart,\n",
    "                    'wstart':wstart,\n",
    "                    'ws':ws,\n",
    "                    }\n",
    "                u,v = self.ncc_calc(int(num_levels), pyramid_imgs, ind, sub_block)\n",
    "                U[i,j]=u\n",
    "                V[i,j]=v\n",
    "        # now call the routine to plot the motion vector:\n",
    "        self.plotflow(ref_im, gridX, gridY, U, V, 1, 0.3)\n",
    "        plt.hist(U.flatten())\n",
    "        plt.hist(V.flatten())\n",
    "        return\n",
    "\n",
    "    def ncc_calc(self, num_levels, pyramid_imgs, ind, sub_block):\n",
    "        r=2\n",
    "        c=2\n",
    "        ws = ind['ws']\n",
    "        for l in range(num_levels):\n",
    "            #print('level ', l)\n",
    "            coarse_im = cv2.cvtColor(pyramid_imgs[(num_levels-1)-l], cv2.COLOR_BGR2GRAY)\n",
    "            if l > 0:\n",
    "                i_new = max((i-1)*(r-1)+i,0)\n",
    "                j_new = max((j-1)*(c-1)+j,0)\n",
    "                #print(i_new, j_new)\n",
    "                rstart = max(i_new-ws,0)\n",
    "                rend = min(i_new+ws,ind['h'])\n",
    "                cstart = max(j_new-ws,0)\n",
    "                cend = min(j_new+ws,ind['w'])\n",
    "                coarse_im = coarse_im[rstart:rend, cstart:cend]\n",
    "            block_norm = sub_block - np.mean(sub_block)\n",
    "            block_norm /= (np.sum(block_norm**2))**0.5\n",
    "            coarse_norm = coarse_im - np.mean(coarse_im)\n",
    "            coarse_norm /= (np.sum(coarse_norm**2)**0.5)\n",
    "            #print(coarse_norm.shape)\n",
    "            ncc_output = correlate2d(coarse_norm, block_norm, 'same')\n",
    "            i, j = np.unravel_index(ncc_output.argmax(),ncc_output.shape)\n",
    "            # motion vector estimation\n",
    "            if l==num_levels-1:\n",
    "                #u = j_new - ind['h'] - ind['hstart'] + j\n",
    "                #v = i_new - ind['w'] - ind['wstart'] + i\n",
    "                #u = cstart - ind['wstart'] + j\n",
    "                #v = rstart - ind['hstart'] + i\n",
    "                u = cstart + j\n",
    "                v = rstart + i\n",
    "        return u,v\n",
    "\n",
    "    def poc_f(self, choice, path):\n",
    "        Img1, Img2 = self.get_seq(choice, path)\n",
    "        ref_im = cv2.cvtColor(Img1, cv2.COLOR_BGR2GRAY)\n",
    "        cur_im = cv2.cvtColor(Img2, cv2.COLOR_BGR2GRAY)\n",
    "        h,w = ref_im.shape\n",
    "        hstart, hend,wstart,wend = 0,0,0,0\n",
    "        bs = 16\n",
    "        x=np.arange(0, w, bs)\n",
    "        y=np.arange(0, h, bs)\n",
    "        gridX, gridY = np.meshgrid(x,y)\n",
    "        H, W = gridX.shape # the height and width of output \n",
    "        U = np.zeros((H, W))\n",
    "        V = np.zeros((H, W))\n",
    "        for i in range(H):\n",
    "            if hend+bs > h:\n",
    "                hstart = h-bs\n",
    "                hend = h\n",
    "                hsc = h-2*bs\n",
    "                hec = h\n",
    "            else:\n",
    "                hstart = hend\n",
    "                hend += bs\n",
    "                hsc = hstart-bs\n",
    "                hec = hend+bs\n",
    "            if hstart-bs < 0:\n",
    "                hsc = 0\n",
    "                hec = hend + 2*bs                \n",
    "            for j in range(W):\n",
    "                if wend+bs > w:\n",
    "                    wstart = w-bs\n",
    "                    wend =w\n",
    "                    wsc = w - 2*bs\n",
    "                    wec = w\n",
    "                else:\n",
    "                    wstart = wend\n",
    "                    wend += bs\n",
    "                    wsc = wstart - bs\n",
    "                    wec = wend+bs\n",
    "                if wstart-bs<0:\n",
    "                    wsc = 0\n",
    "                    wec = wend + 2*bs\n",
    "                sub_block_r = ref_im[hstart:hend, wstart:wend]\n",
    "                #sub_block_c = cur_im[hstart:hend, wstart:wend]\n",
    "                sub_block_c = cur_im[hsc:hec, wsc:wec]\n",
    "                u,v = self.poc_calc(sub_block_r, sub_block_c, hsc, wsc)\n",
    "                U[i,j]=u\n",
    "                V[i,j]=v\n",
    "        # now call the routine to plot the motion vector:\n",
    "        self.plotflow(ref_im, gridX, gridY, U, V, 1, 0.3)\n",
    "        plt.hist(U.flatten())\n",
    "        plt.hist(V.flatten())\n",
    "        return\n",
    "\n",
    "    def poc_calc(self, rim, cim, hstart, wstart):\n",
    "        h, w = rim.shape\n",
    "        hc, wc = cim.shape\n",
    "        bs = 16\n",
    "        hsc, hec, wsc, wec = 0, 0, 0, 0\n",
    "        hc_check, wc_check = True, True\n",
    "        temp_max = []\n",
    "        u_temp,v_temp = [], []\n",
    "        for i in range(hc):\n",
    "            if hc_check == False:\n",
    "                continue\n",
    "            if hsc+bs > hc:\n",
    "                hsc = hc-bs\n",
    "                hec = hc\n",
    "                hc_check = False\n",
    "            else:\n",
    "                hsc += 1\n",
    "                hec = hsc + bs\n",
    "            for j in range(wc):\n",
    "                if wc_check == False:\n",
    "                    continue\n",
    "                if wec+bs > wc:\n",
    "                    wsc = wc-bs\n",
    "                    wec = wc\n",
    "                    wc_check = False\n",
    "                else:\n",
    "                    wsc += 1\n",
    "                    wec = wsc + bs\n",
    "                #print(cim.shape)\n",
    "                cim_sub = cim[hsc:hec, wsc:wec]\n",
    "                #print(hsc, hec, wsc, wec)\n",
    "                #print(cim_sub.shape)\n",
    "                hanning = [np.hanning(h), np.hanning(w)]\n",
    "                window = hanning[1].reshape(hanning[1].shape[0],1)*hanning[0]\n",
    "                #print(window.shape)\n",
    "                rim1 = np.float64(rim)*window\n",
    "                cim1 = np.float64(cim_sub)*window\n",
    "                fft_im1 = np.fft.fft2(rim1)\n",
    "                fft_im2 = np.fft.fft2(cim1)\n",
    "                cross_power = fft_im1 * np.ma.conjugate(fft_im2)\n",
    "                #cross_power = fft_im1 * np.conjugate(fft_im2)/np.absolute(fft_im1*np.conjugate(fft_im2))\n",
    "                cross_power/= np.absolute(cross_power)\n",
    "                ncc_output = np.real(np.fft.ifft2(cross_power))\n",
    "                i, j = np.unravel_index(ncc_output.argmax(),ncc_output.shape)\n",
    "                u = wsc+j\n",
    "                v = hsc+i\n",
    "                temp_max.append(ncc_output[i,j])\n",
    "                u_temp.append(u)\n",
    "                v_temp.append(v)\n",
    "        max_ind = np.argmax(temp_max)\n",
    "        u = u_temp[max_ind]\n",
    "        v = v_temp[max_ind]\n",
    "        return u, v\n",
    "\n",
    "    def gradient_xyt(self, I1, I2, x, y):\n",
    "        h, w = I1.shape\n",
    "        x = int(x)\n",
    "        y = int(y)\n",
    "        \n",
    "        Ix = (x>0 and x< (w-1) and y>=0 and y<h ) and (I1[y, x+1] - I1[y, x-1])/2 or 0\n",
    "        Iy = (x>=0 and x<w and y>0 and y< (h-1) ) and (I1[y+1, x] - I1[y-1, x])/2 or 0\n",
    "        It = (x>=0 and x<w and y>=0 and y<h) and I2[y,x] - I1[y,x] or 0\n",
    "        return (Ix, Iy, It)\n",
    "\n",
    "    def getAb(self, I1, I2, x, y, n):\n",
    "        A = np.zeros((n*n, 2))\n",
    "        b = np.zeros(n*n)\n",
    "        \n",
    "        # compute the relative positions of pixels in a window\n",
    "        offset = np.arange(0, n) - np.floor(n/2); \n",
    "        dx, dy = np.meshgrid(offset, offset);\n",
    "        dx = dx.reshape(n*n, 1);\n",
    "        dy = dy.reshape(n*n, 1);\n",
    "        \n",
    "        # compute the elements of A and b\n",
    "        for i in range(0, n*n):\n",
    "            Ix, Iy, It = self.gradient_xyt(I1, I2, x+dx[i], y+dy[i])\n",
    "            A[i, 0] = Ix \n",
    "            A[i, 1] = Iy\n",
    "            b[i] = -It\n",
    "            \n",
    "        return (A, b)\n",
    "\n",
    "    ##  flow->motion\n",
    "    def estimate_flow_at_xy(self, I1, I2, x, y, n):\n",
    "        A, b = self.getAb(I1, I2, x, y, n)\n",
    "     \n",
    "        # least square \n",
    "        # https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.linalg.lstsq.html  \n",
    "        result = np.linalg.lstsq(np.matmul(A.T, A), np.matmul(A.T, b))\n",
    "        # result = np.linalg.lstsq(A, b)\n",
    "        v = result[0]\n",
    "        return v\n",
    "\n",
    "    def estimate_flow(self, I1, I2, gridX, gridY, n):\n",
    "        H, W = gridX.shape # the height and width of output \n",
    "        U = np.zeros((H, W))\n",
    "        V = np.zeros((H, W))\n",
    "        \n",
    "        # iterate over the grid\n",
    "        for i in range(0, H):\n",
    "            for j in range(0, W):\n",
    "                v =  self.estimate_flow_at_xy(I1, I2,gridX[i, j], gridY[i, j], n)\n",
    "                U[i, j] = v[0]\n",
    "                V[i, j] = v[1]\n",
    "        return (U, V)\n",
    "\n",
    "    def kl_f(self, choice, path):\n",
    "        Img1, Img2 = self.get_seq(choice, path)\n",
    "        #Img1 = cv2.cvtColor(Img1, cv2.COLOR_BGR2GRAY)\n",
    "        #Img2 = cv2.cvtColor(Img2, cv2.COLOR_BGR2GRAY)\n",
    "        Img1 = self.gaussian_blur(cv2.cvtColor(Img1, cv2.COLOR_BGR2GRAY))\n",
    "        Img2 = self.gaussian_blur(cv2.cvtColor(Img2, cv2.COLOR_BGR2GRAY))\n",
    "        H, W = Img1.shape\n",
    "        gridsz = 9\n",
    "        wsz  = 21\n",
    "        x = np.arange(0, W-gridsz, gridsz) + np.floor(gridsz/2);\n",
    "        y = np.arange(0, H-gridsz, gridsz) + np.floor(gridsz/2);\n",
    "        gridX, gridY = np.meshgrid(x,y);\n",
    "        U, V = self.estimate_flow(Img1, Img2, gridX, gridY, wsz)\n",
    "        self.plotflow(Img1, gridX, gridY, U, V, 1, 5)\n",
    "        return\n",
    "\n",
    "\n",
    "    def hs_f(self, choice, path):\n",
    "        Img1, Img2 = self.get_seq(choice, path)\n",
    "        Img1 = self.gaussian_blur(cv2.cvtColor(Img1, cv2.COLOR_BGR2GRAY)).astype(np.float)\n",
    "        Img2 = self.gaussian_blur(cv2.cvtColor(Img2, cv2.COLOR_BGR2GRAY)).astype(np.float)\n",
    "        num_iter = 100\n",
    "        reg_const = 1\n",
    "        h, w = Img1.shape\n",
    "        U = np.zeros((h,w))\n",
    "        V = np.zeros((h,w))\n",
    "        \n",
    "        Ix, Iy, It = self.gradient_hs(Img1, Img2)\n",
    "        fs = np.array([[1/12,1/6,1/12],[1/6,0,1/6],[1/12,1/6,1/12]], dtype = float)\n",
    "        for i in range(num_iter):\n",
    "            u_bar = cv2.filter2D(U, -1, fs)\n",
    "            v_bar = cv2.filter2D(V, -1, fs)\n",
    "            U = u_bar - Ix*((Ix*u_bar + Iy*v_bar + It)/(reg_const**2+Ix**2+Iy**2))\n",
    "            V = v_bar - Iy*((Ix*u_bar + Iy*v_bar + It)/(reg_const**2+Ix**2+Iy**2))\n",
    "        ws = 5\n",
    "        x=np.arange(0, w, ws)\n",
    "        y=np.arange(0, h, ws)\n",
    "        gridX, gridY = np.meshgrid(x,y)\n",
    "        g_x_s, g_y_s = gridX.shape\n",
    "        U_plot = np.zeros((g_x_s, g_y_s))\n",
    "        V_plot = np.zeros((g_x_s, g_y_s))\n",
    "        jc, kc = 0, 0\n",
    "        for j in range(0, len(U), ws):\n",
    "            kc = 0\n",
    "            for k in range(0, len(V), ws):\n",
    "                U_plot[jc, kc] = U[j,k]\n",
    "                V_plot[jc, kc] = V[j,k]\n",
    "                kc += 1\n",
    "            jc+=1\n",
    "        self.plotflow(Img1, gridX, gridY, np.array(U_plot), np.array(V_plot), 1, 0.3) # for worm, set threshold to 5\n",
    "        return\n",
    "\n",
    "    def gradient_hs(self, Img1, Img2):\n",
    "        k_x = np.array([[-1/4, 1/4],[-1/4, 1/4]], dtype = float)\n",
    "        k_y = np.array([[-1/4, -1/4],[1/4, 1/4]], dtype = float)\n",
    "        k_t = np.array([[1/4, 1/4],[1/4, 1/4]], dtype = float)\n",
    "        #Ix = cv2.filter2D(Img1,-1,k_x)+cv2.filter2D(Img2,-1,k_x)\n",
    "        #Iy = cv2.filter2D(Img1,-1,k_y)+cv2.filter2D(Img2,-1,k_y)\n",
    "        #It = cv2.filter2D(Img1,-1,k_t)-cv2.filter2D(Img2,-1,k_t)\n",
    "        Ix = signal.convolve2d(Img1, k_x, 'same')+signal.convolve2d(Img2,k_x, 'same')\n",
    "        Iy = signal.convolve2d(Img1, k_y, 'same')+signal.convolve2d(Img2,k_y, 'same')\n",
    "        It = signal.convolve2d(Img1, k_t, 'same')-signal.convolve2d(Img2,k_t, 'same')\n",
    "        return Ix, Iy, It\n",
    "\n",
    "    def klt_track(self, choice, path):\n",
    "        img_folder, fname_ip = self.get_seq(choice, path)\n",
    "        vcapt = cv2.VideoCapture(img_folder + fname_ip)\n",
    "        frame_width = int(vcapt.get(3))\n",
    "        frame_height = int(vcapt.get(4))\n",
    "        out = cv2.VideoWriter('outpy.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width,frame_height))\n",
    "        if (vcapt.isOpened()== False):\n",
    "            print(\"Error opening video stream or file\")\n",
    "        while(vcapt.isOpened()):\n",
    "            ret, frame = vcapt.read()\n",
    "            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            vis = frame.copy()\n",
    "            print('Frame: ', self.frame_idx)\n",
    "            if len(self.tracks) > 0:\n",
    "                img0, img1 = self.prev_gray, frame_gray\n",
    "                p0 = np.float32([tr[-1] for tr in self.tracks]).reshape(-1, 1, 2)\n",
    "                p1 = self.hs_track_point(img0, img1, p0)\n",
    "                #print('returned p1')\n",
    "                '''p0r = self.hs_track_point(img1, img0, p1)\n",
    "                print('returned p0r')\n",
    "                d = abs(p0-p0r).reshape(-1, 2).max(-1)\n",
    "                print(d)\n",
    "                good = d < 1'''\n",
    "                new_tracks = []\n",
    "                new_tracks_poly = []\n",
    "                '''for tr, (x, y), good_flag in zip(self.tracks, p1.reshape(-1, 2), good):\n",
    "                    if not good_flag:\n",
    "                        continue'''\n",
    "                for tr, tr_poly, (x, y) in zip(self.tracks, self.tracks_poly, p1.reshape(-1, 2)):\n",
    "                    tr.append((x, y))\n",
    "                    tr_poly.append((y,x))\n",
    "                    if len(tr) > self.track_len:\n",
    "                        del tr[0]\n",
    "                        del tr_poly[0]\n",
    "                    new_tracks.append(tr)\n",
    "                    new_tracks_poly.append(tr_poly)\n",
    "                    cv2.circle(vis, (int(y), int(x)), 2, (0, 255, 0), -1)\n",
    "                self.tracks = new_tracks\n",
    "                self.tracks_poly = new_tracks_poly\n",
    "                cv2.polylines(vis, [np.int32(tr) for tr in self.tracks_poly], False, (0, 255, 0))\n",
    "                #cv2.polylines(vis, [np.int32(tr) for tr in self.tracks], False, (0, 255, 0))\n",
    "                #draw_str(vis, (20, 20), 'track count: %d' % len(self.tracks))\n",
    "                \n",
    "            if self.frame_idx % self.detect_interval == 0:\n",
    "                p = cv2.cornerHarris(frame_gray,2,3,0.04)\n",
    "                #vis[p>0.01*p.max()]=[0,255,0]\n",
    "                pf = np.where(p>0.01*p.max())\n",
    "                pf_list = list(zip(*pf))\n",
    "                if pf_list is not None:\n",
    "                    #for x, y in np.float32(pf).reshape(-1, 2):\n",
    "                        #print(x,y)\n",
    "                    for x,y in pf_list:\n",
    "                        self.tracks.append([(x, y)])\n",
    "                        self.tracks_poly.append([(y,x)])\n",
    "                        # to display the corner points\n",
    "                        #cv2.imshow('vis', vis)\n",
    "\n",
    "            '''if self.frame_idx % self.detect_interval == 0:\n",
    "                mask = np.zeros_like(frame_gray)\n",
    "                mask[:] = 255\n",
    "                for x, y in [np.int32(tr[-1]) for tr in self.tracks]:\n",
    "                    cv2.circle(mask, (x, y), 5, 0, -1)\n",
    "                p = cv2.goodFeaturesToTrack(frame_gray, mask = mask, **feature_params)\n",
    "                if p is not None:\n",
    "                    for x, y in np.float32(p).reshape(-1, 2):\n",
    "                        self.tracks.append([(x, y)])'''\n",
    "            \n",
    "            self.prev_gray = frame_gray\n",
    "            cv2.imshow('lk_track', vis)\n",
    "            out.write(vis)\n",
    "            self.frame_idx += 1\n",
    "\n",
    "            ch = cv2.waitKey(1)\n",
    "            if ch == 27:\n",
    "                break\n",
    "        return\n",
    "\n",
    "    def hs_track_point(self, Img1, Img2, p):\n",
    "        Img1 = self.gaussian_blur(Img1).astype(np.float)\n",
    "        Img2 = self.gaussian_blur(Img2).astype(np.float)\n",
    "        num_iter = 10\n",
    "        reg_const = 1\n",
    "        h, w = Img1.shape\n",
    "        U = np.zeros((h,w))\n",
    "        V = np.zeros((h,w))\n",
    "        \n",
    "        Ix, Iy, It = self.gradient_hs(Img1, Img2)\n",
    "        fs = np.array([[1/12,1/6,1/12],[1/6,0,1/6],[1/12,1/6,1/12]], dtype = float)\n",
    "        for i in range(num_iter):\n",
    "            u_bar = cv2.filter2D(U, -1, fs)\n",
    "            v_bar = cv2.filter2D(V, -1, fs)\n",
    "            U = u_bar - Ix*((Ix*u_bar + Iy*v_bar + It)/(reg_const**2+Ix**2+Iy**2))\n",
    "            V = v_bar - Iy*((Ix*u_bar + Iy*v_bar + It)/(reg_const**2+Ix**2+Iy**2))\n",
    "        UV = []\n",
    "        jc = 0\n",
    "        for pt in range(len(p)):\n",
    "            xpt, ypt = p[pt][0]\n",
    "            xpt = min(xpt, h-1)\n",
    "            ypt = min(ypt, w-1)\n",
    "            UV.append([(int(xpt)+V[int(xpt), int(ypt)],int(ypt)+U[int(xpt),int(ypt)])])\n",
    "            #UV.append([(int(ypt)+U[int(xpt),int(ypt)],int(xpt)+V[int(xpt), int(ypt)])])\n",
    "        return np.array(UV)\n",
    "    \n",
    "    def kal_track(self, choice, path):\n",
    "        Img1, Img2 = self.get_seq(choice, path)\n",
    "        pass\n",
    "\n",
    "    def normalize_fn(self, choice, path):\n",
    "        pass\n",
    "\n",
    "    def gaussian_blur(self, img):\n",
    "        fs = 3\n",
    "        Img_final = cv2.GaussianBlur(img, (fs,fs),0)\n",
    "        Img2 = Img_final.astype(np.uint8)\n",
    "        return Img_final\n",
    "\n",
    "    def remove_r_c(self, img):\n",
    "        return img[::2,::2,:]\n",
    "\n",
    "    def pyramid_gaussian(self, img):\n",
    "        num_levels = input('Enter the number of levels in the pyramid: ')\n",
    "        pyramid_img = [img]\n",
    "        for l in range(int(num_levels)-1):\n",
    "            img = self.gaussian_blur(img)\n",
    "            img = self.remove_r_c(img)\n",
    "            print(img.shape)\n",
    "            pyramid_img.append(img)\n",
    "        return pyramid_img, num_levels\n",
    "\n",
    "    def plot_hist(self):\n",
    "        pass\n",
    "    \n",
    "    def plot_motion(self):\n",
    "        pass\n",
    "\n",
    "    def video_to_frames(self, filename, path):\n",
    "        directory = os.fsencode(path)\n",
    "        vcapt = cv2.VideoCapture(path + filename)\n",
    "        captured, frame = vcapt.read()\n",
    "        count = 0\n",
    "        captured = True\n",
    "        while captured:\n",
    "            cv2.imwrite(os.path.join(path,\"frame%d.jpg\" % count), frame)\n",
    "            success,frame = vcapt.read()\n",
    "            count += 1\n",
    "        return\n",
    "    \n",
    "    def get_seq(self, choice, img_folder):\n",
    "        directory = os.fsencode(img_folder)\n",
    "        vid = input('Convert video to seq images ? enter y or n: ')\n",
    "        if vid == 'y':\n",
    "            fname_ip = input('Enter the name of the video file: ')\n",
    "            for file in os.listdir(img_folder):\n",
    "                filename = os.fsdecode(file)\n",
    "                if not (fname_ip == filename):\n",
    "                    continue\n",
    "                self.video_to_frames(filename,img_folder)\n",
    "                break\n",
    "        # now get the two sequences to plot motion vector\n",
    "        if choice == 'klt_track' or choice == 'kal_track':\n",
    "                if vid == 'n':\n",
    "                    fname_ip = input('Enter the name of the video file: ')\n",
    "                print('Showing input video')\n",
    "                vcapt = cv2.VideoCapture(img_folder + fname_ip)\n",
    "                if (vcapt.isOpened()== False):\n",
    "                    print(\"Error opening video stream or file\")\n",
    "                while(vcapt.isOpened()):\n",
    "                    ret, frame = vcapt.read()\n",
    "                    if ret == True:\n",
    "                        cv2.imshow('Frame',frame)\n",
    "                        if cv2.waitKey(25) & 0xFF == ord('e'):\n",
    "                            break\n",
    "                    else:\n",
    "                        break\n",
    "                vcapt.release()\n",
    "                return img_folder, fname_ip\n",
    "        else:\n",
    "                ip1 = input('Enter the name of the reference image: ')\n",
    "                ip2 = input('Enter the name of the current image: ')\n",
    "                if os.fsencode(ip1) not in os.listdir(directory) or os.fsencode(ip2) not in os.listdir(directory):\n",
    "                    print('wrong input file name')\n",
    "                    return\n",
    "                Img1 = self.read_image(img_folder, ip1)\n",
    "                Img2 = self.read_image(img_folder, ip2)\n",
    "                if Img1 is None or Img2 is None:\n",
    "                    print('Input image is None, returning')\n",
    "                    return\n",
    "                cv2.namedWindow('Reference Image')\n",
    "                cv2.imshow('Reference Image', Img1)\n",
    "                cv2.namedWindow('Current Image')\n",
    "                cv2.imshow('Current Image', Img2)\n",
    "                cv2.waitKey(0)\n",
    "                return Img1, Img2\n",
    "            \n",
    "    def read_image(self, directory, filename):\n",
    "        #if filename.startswith(\"f\") and (filename.endswith(\".jpg\") or filename.endswith(\".bmp\") or filename.endswith(\".png\") or filename.endswith(\".gif\")):\n",
    "        if (filename.endswith(\".jpg\") or filename.endswith(\".bmp\") or filename.endswith(\".png\") or filename.endswith(\".gif\")):\n",
    "            print(filename)\n",
    "            img = cv2.imread(directory + filename,-1)\n",
    "            if img is None:\n",
    "                print('Invalid image:' + filename)\n",
    "                return None\n",
    "            return img\n",
    "\n",
    "    def main(self, choice, path):\n",
    "        options = {'cor_f':self.cor_f,\n",
    "                   'poc_f':self.poc_f,\n",
    "                   'kl_f': self.kl_f,\n",
    "                   'hs_f': self.hs_f,\n",
    "                   'klt_track':self.klt_track,\n",
    "                   'kal_track':self.kal_track,\n",
    "            }\n",
    "        options[choice](choice, path)\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # creating an instance of the motion estimation class\n",
    "    me_class = Motion_est()\n",
    "\n",
    "    # Call to the main function\n",
    "    tic = time.time()\n",
    "    print('Choices are : \\n 1. Correlation(cor_f) \\n 2. Phase Correlation (poc_f) \\n 3. Lucas Kanade (kl_f) \\n 4. Horn&Schunck (hs_f) \\n 5. KLT tracker (klt_track) and \\n 6. Kalman+Hanning(kal_track)')\n",
    "    choice_v = input(\"Enter the choice: \")\n",
    "    path = input(\"Enter the folder to the seq or video: \")\n",
    "    # for path enter ..\\\\input\\\\\n",
    "    me_class.main(choice_v, path)\n",
    "    toc = time.time() - tic\n",
    "    print(\"Running time: \" + str(toc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Referenced quote - Following Horn’s taxonomy, the motion field is the 2D projection of the 3D motion of surfaces in the world, whereas the optical flow is the apparent motion of the brightness patterns in the image.\n",
    "\n",
    "## Horn & Schunck Algorithm :\n",
    "For implementing this algorithm, I used the following two articles as reference to understand the algorithm and then implemented it from scratch :\n",
    "http://www.journal.au.edu/au_techno/2011/july2011/journal151_article02.pdf\n",
    "https://en.wikipedia.org/wiki/Horn%E2%80%93Schunck_method\n",
    "\n",
    "As listed in wikipedia, the optical flow computation by Horn and schunck involves the following steps :\n",
    "1. Smooth the two image sequences\n",
    "2. Compute the gradients, I used the following kernel for Ix, Iy and It :\n",
    "        k_x = np.array([[-1/4, 1/4],[-1/4, 1/4]])\n",
    "        k_y = np.array([[-1/4, -1/4],[1/4, 1/4]])\n",
    "        k_t = np.array([[1/4, 1/4],[1/4, 1/4]])\n",
    "        Ix = conv(Im1, k_x) + conv(Im2, k_y)\n",
    "        Iy = conv(Im1, k_y) + conv(Im2, k_y)\n",
    "        It = conv(Im1, k_t) - conv(Im2, k_t)\n",
    "3. After obtaining the gradients, I find the local weighted average of the neighborhood using a filter kernel. \n",
    "4. Finally the motion vector is updated using the following equations :\n",
    "\n",
    "![Alt text](imgs/hs_formula.png?raw=true \"hs_formula\")\n",
    "\n",
    "This algorithm is iterative, so higher the number of iterations and larger the value of regularization constant, I observed that the results are better.\n",
    "\n",
    "For the sphere, the algorithm produced great results :\n",
    "\n",
    "![Alt text](imgs/HS_Sphere_Correct.png?raw=true \"HS_Sphere_Correct\")\n",
    "\n",
    "This is just with 100 iterations.\n",
    "\n",
    "![Alt text](imgs/HS_Worm_Correct2.png?raw=true \"HS_Worm_Correct2\")\n",
    "\n",
    "![Alt text](imgs/HS_Seq_Correct.png?raw=true \"HS_Seq_Correct\")\n",
    "\n",
    "Above is the result of the HS algorithm for the sequence image. The motion vector looks good though there are noisy vectors, the other areas look good.\n",
    "\n",
    "I also had some videos of an earthworm moving around in a white background from a previous project I worked with the Bio robotics team, was interested in testing out the algorithm on the earthworm sequences and here is the result: \n",
    "\n",
    "Old Image : (frame10.jpg)\n",
    "\n",
    "![Alt text](imgs/frame10.jpg?raw=true \"frame10\")\n",
    "\n",
    "Current image: (frame18.jpg)\n",
    "\n",
    "![Alt text](imgs/frame18.jpg?raw=true \"frame18\")\n",
    "\n",
    "Here is the motion vector estimated by the HS algorithm :\n",
    "![Alt text](imgs/HS_Worm_Correct.png?raw=true \"HS_Worm_Correct\")\n",
    "\n",
    "Even when the motion between the two sequence images was large, the algorithm was able to identify the motion decently. For eg., when reference image was the 'frame10' image and I used the below frame783 image as current image,\n",
    "\n",
    "![Alt text](imgs/frame783.jpg?raw=true \"frame783\")\n",
    "\n",
    "As we can see from the results, though there is noise, for majority part, the motion vector has the right magnitude and orientation.\n",
    "![Alt text](imgs/HS_Worm_Correct_frame10_frame783.png?raw=true \"HS_Worm_Correct_frame10_frame783\")\n",
    "\n",
    "The given gradient constraint solution (Lucas-Kanade) provided in the demo did not do a great job. But this method with some improvements will definitely provide good motion vector estimates.\n",
    "Result from demo GCE solution (Lucas Kanade):\n",
    "![Alt text](imgs/KL_smoothed_no.png?raw=true \"KL_smoothed_no\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Earthworm Tracking :\n",
    "The above implementation motivated me to track the corner points of the earthworm through the video and hence I extended the HS algorithm to track selective points. The points in this case are the corner points detected by harris corner detectors.\n",
    "\n",
    "Here is the tracking video :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<video controls src=\"../imgs/outpy.avi\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the video does not play here, please do check the output directory, have included the video here. The tracking is not perfect but it works decently with just a basic implementation of the Horn and Schunck algorithm. This is promising, finding better ways to improve this algorithm (eg. using pyramids, etc) should improve the tracking results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
