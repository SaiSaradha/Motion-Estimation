{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, I have experimented with an interesting neural network topic - 'Autoencoders'. The code has been written in Python with Tensorflow as the backend. Four different types of autoencoders have been implemented and simple analysis comparing the networks in general and the autoencoder types has also been done. I have implemented all autoencoders from scratch and the types are :\n",
    "1. Shallow Autoencoder (simple network with one hidden layer)\n",
    "2. Deep Autoencoder (larger network with #of hidden layers specified by the user)\n",
    "3. Sparse Autoencoder (introduced sparsity in the network by activating minimal number of neurons to study the performance)\n",
    "4. Denoising Autoencoder (introduce noise in the images and then let the autoencoder network learn the original images)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's briefly review the autoencoders, the algorithm and different types and then discuss about the implementation and results.\n",
    "Autoencoders:\n",
    "Autoencoder is a neural network that is mostly used for dimensionality reduction purposes and by that I mean, the image is encoded into a lower-dimensionality at one end and then the original image is reconstructed at the decoding end. So, in a way the autoencoders are similar to PCA and t-SNE and other dimensionality reduction techniques. They are also used for image denoising (we have explored this in denoising autoencoders section) and are believed to learn good representations (at lower dimension). \n",
    "\n",
    "Auto-encoder image (image taken from Stanford UFLDL page)\n",
    "\n",
    "![Alt text](imgs/AEN_image.PNG?raw=true \"AEN_image\")\n",
    "\n",
    "So usually the autoencoder has two main components - the encoder and decoder,\n",
    "Input --> Encoder --> Encoded output --> Decoder --> Output (Input_hat)\n",
    "\n",
    "In this exercise, I have first implemented shallow and deep AENs from scratch defining each of the layers - conv, max_pool, fc (fully connected) and deconv (deconvolution). I have also worked directly with the tf.layers.conv2D functions and rewritten the code. The four hyperparameters essential for designing a conv net are :\n",
    "1. Output Depth 2. Stride and 3. Zero padding size\n",
    "In this exercise, I have designed my own filters and chose values for depth, stride and zero padding so as to reconstruct the original images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from scipy import ndimage\n",
    "import scipy\n",
    "import time\n",
    "from math import sqrt, cos, pi\n",
    "import matplotlib \n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from skimage import transform\n",
    "import tensorflow.contrib.layers as layers\n",
    "\n",
    "class AEN_analysis:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.train_data = []\n",
    "        self.train_labels = []\n",
    "        self.test_data = []\n",
    "        self.test_labels = []\n",
    "        self.data_classes = {}\n",
    "\n",
    "        #MNIST Data\n",
    "        self.data = []\n",
    "        self.test = []\n",
    "        self.eval_data = []\n",
    "\n",
    "        # network_parameters initial setup (can be modified later if required\n",
    "        # with the nw_params_modify function:\n",
    "        self.batch_size = 1000\n",
    "        self.image_shape = (28, 28, 1)\n",
    "        self.image_shape_batch = (self.batch_size, self.image_shape[0], self.image_shape[1], self.image_shape[2])\n",
    "        self.learning_rate = 0.01\n",
    "        self.epoch_count = 10\n",
    "        self.show_recon_num = 10\n",
    "    \n",
    "    #CIFAR dataset prelim options - load data, show histo of features and show original images:\n",
    "    def unpickle(self, file):\n",
    "        with open(file, 'rb') as fo:\n",
    "            dict = pickle.load(fo, encoding='bytes')\n",
    "        return dict\n",
    "\n",
    "    def load_data_cifar(self):\n",
    "        # Load the CIFAR dataset, there are 5 batches of training images, let's load\n",
    "        # each of them and append them together\n",
    "        print('loading data of batch: ')\n",
    "        for i in range(5):\n",
    "            print(str(i+1))\n",
    "            this_data = self.unpickle('dataset_CIFAR/data_batch_'+str(i+1))\n",
    "            # the dictionary has the following elements - batch_label, labels, data and filenames\n",
    "            # we only need the data and the labels\n",
    "            if i == 0:\n",
    "                self.train_data = this_data[b'data']\n",
    "                self.train_labels = this_data[b'labels']\n",
    "                continue\n",
    "            self.train_data = np.vstack((self.train_data, this_data[b'data']))\n",
    "            self.train_labels.extend(this_data[b'labels'])\n",
    "        # now load the test data\n",
    "        test_all_data = self.unpickle('dataset_CIFAR/test_batch')\n",
    "        self.test_data = test_all_data[b'data']\n",
    "        self.test_labels = test_all_data[b'labels']\n",
    "        # this data_class dict object in turn has following elements - num_cases_per_batch,\n",
    "        # label_names and num_vis. We may need only label_names mostly, hence taking only that\n",
    "        self.data_classes = self.unpickle('dataset_CIFAR/batches.meta')[b'label_names']\n",
    "        return\n",
    "\n",
    "    def show_original_data_cifar(self):\n",
    "        \n",
    "        # show the original images (one image from each of the 10 categories)\n",
    "        num_eg = 5\n",
    "        indi = [np.where(np.array(self.train_labels)==lab)[:num_eg] for lab in range(0, len(self.data_classes))]\n",
    "        # plotting the images\n",
    "        fig, aa = plt.subplots(len(self.data_classes),num_eg,figsize=(32, 32))\n",
    "        for class_id in range(len(self.data_classes)):\n",
    "            for i in range(num_eg):\n",
    "                #aa[class_id,i].imshow(np.reshape(self.train_data[indi[class_id][0][i]],(32,32,3)))\n",
    "                aa[class_id, i].imshow(np.dstack((self.train_data[indi[class_id][0][i]][:1024].reshape((32,32,1)),self.train_data[indi[class_id][0][i]][1024:2048].reshape((32,32,1)),self.train_data[indi[class_id][0][i]][2048:].reshape((32,32,1)))))\n",
    "                aa[class_id,i].axis('off')\n",
    "\n",
    "        fig.suptitle('{} sample images from each class'.format(5))\n",
    "        plt.show()\n",
    "        return\n",
    "\n",
    "    def load_data_mnist(self):\n",
    "        data = input_data.read_data_sets('MNIST_data')\n",
    "        self.data = data.train.images\n",
    "        self.test = data.test.images\n",
    "        self.eval_data = data.validation\n",
    "        return data\n",
    "    \n",
    "    # performance - accuracy, precision, recall and ROC (only for classification AEN all options):\n",
    "    def performance(self):\n",
    "        pass\n",
    "\n",
    "    # loss comparison with different depths of aen (separate exp):\n",
    "    def loss_compare(self):\n",
    "        pass\n",
    "    \n",
    "    # creation of the different layers - convolution layer (conv), deconvolution layer(deconv),\n",
    "    # max pool layer (max_pool) and fully connected layer (fc)\n",
    "    def conv(self, inp, inp_name, fs, strde, pad='SAME', non_linearity=tf.nn.relu):\n",
    "        Bi,Hi,Wi,Di = inp.shape\n",
    "        Fh,Fw,Fd = fs\n",
    "        Sh,Sw = strde\n",
    "        with tf.variable_scope(inp_name):\n",
    "            Weight_m = tf.get_variable('weights',[Fh,Fw,Di,Fd])\n",
    "            Biases_m = tf.get_variable('biases',[Fd])\n",
    "            conv_v = tf.nn.bias_add(tf.nn.conv2d(inp, Weight_m, [1,Sh,Sw,1],pad),Biases_m)\n",
    "            final_conv = non_linearity(conv_v,inp_name)\n",
    "            return final_conv\n",
    "\n",
    "    def deconv(self, inp, inp_name, fs, strde, pad='SAME', non_linearity=tf.nn.relu):\n",
    "        Bi,Hi,Wi,Di = inp.shape\n",
    "        Fh,Fw,Fd = fs\n",
    "        Sh,Sw = strde\n",
    "        if pad=='VALID':\n",
    "            Ho = (Hi-1)*Sh+Fh\n",
    "            Wo = (Wi-1)*Sw+Fw\n",
    "        elif pad=='SAME':\n",
    "            Ho = Hi*Sh\n",
    "            Wo = Wi*Sw\n",
    "        output_shape = [self.batch_size, int(Ho), int(Wo), Fd]\n",
    "        with tf.variable_scope(inp_name):\n",
    "            Weight_m = tf.get_variable('weights',[Fh,Fw,Fd,Di])\n",
    "            Biases_m = tf.get_variable('biases',[Fd])\n",
    "            conv_v = tf.nn.bias_add(tf.nn.conv2d_transpose(inp, Weight_m, output_shape, [1,Sh,Sw,1],pad),Biases_m)\n",
    "            final_deconv = non_linearity(conv_v,inp_name)\n",
    "            return final_deconv\n",
    "\n",
    "    def fc(self, inp, inp_name, output_shape, non_linearity = tf.nn.relu):\n",
    "        with tf.variable_scope(inp_name):\n",
    "            if len(inp.shape)==4:\n",
    "                batch_size, Hi, Wi, Di = inp.shape\n",
    "                input_shape = Hi*Wi*Di\n",
    "                x = tf.reshape(inp,[batch_size, input_shape])\n",
    "            else:\n",
    "                input_shape = inp.shape[1]\n",
    "                x = inp\n",
    "            Weight_m = tf.get_variable('weights',[input_shape, output_shape])\n",
    "            Biases_m = tf.get_variable('biases',[output_shape])\n",
    "            if non_linearity:\n",
    "                fc_output = non_linearity(tf.nn.xw_plus_b(x,Weight_m, Biases_m),inp_name)\n",
    "            else:\n",
    "                fc_output = x\n",
    "            return fc_output\n",
    "\n",
    "    def max_pool(self, inp, fs, strde, pad='SAME'):\n",
    "        Fh, Fw = fs.shape\n",
    "        Sh, Sw = strde.shape\n",
    "        pool_output = tf.nn.max_pool(inp, [1,Fh, Fw, 1],[1,Sh,Sw,1],pad)\n",
    "        return pool_output\n",
    "    \n",
    "    # the two parts of autoencoder - encoder and decoder:\n",
    "    #for normal autoencoder\n",
    "    def encoder(self, inp_im, nh, fs, filt, strd):\n",
    "        for i in range(nh):\n",
    "            this_name = str('conv')+str(i+1)\n",
    "            if i==0:\n",
    "                this_conv = layers.conv2d(inp_im, filt[i], [fs,fs], stride=strd,padding='SAME')\n",
    "                continue\n",
    "            else:\n",
    "                this_conv = layers.conv2d(this_conv, filt[i], [fs,fs], stride=strd,padding='SAME')\n",
    "        print(this_conv.shape)\n",
    "        return this_conv\n",
    "\n",
    "    #for sparse auto encoder:\n",
    "    '''def encoder(self, inp_im, nh, fs, filt, strd):\n",
    "        for i in range(nh):\n",
    "            this_name = str('conv')+str(i+1)\n",
    "            if i==0:\n",
    "                this_conv = tf.layers.conv2d(inp_im, filt[i], [fs,fs], strides=strd,padding='SAME', activity_regularizer=tf.contrib.layers.l2_regularizer(10e-5))\n",
    "                continue\n",
    "            else:\n",
    "                this_conv = tf.layers.conv2d(this_conv, filt[i], [fs,fs], strides=strd,padding='SAME', activity_regularizer=tf.contrib.layers.l2_regularizer(10e-5))\n",
    "        print(this_conv.shape)\n",
    "        return this_conv'''\n",
    "\n",
    "    def decoder(self, inp_im, nh, fs, filt, pad, strd):\n",
    "        #Now the input that is coming here is of size 4 x 4 x 4 (for deep aen)\n",
    "        for i in range(nh):\n",
    "            this_name = str('deconv')+str(i+1)\n",
    "            if i==0:\n",
    "                this_deconv = layers.conv2d_transpose(inp_im, filt[i], [fs[i],fs[i]], stride=strd[i],padding=pad[i])\n",
    "            else:\n",
    "                this_deconv = layers.conv2d_transpose(this_deconv, filt[i], [fs[i], fs[i]], stride = strd[i], padding=pad[i])\n",
    "        print(this_deconv.shape)\n",
    "        return this_deconv\n",
    "    \n",
    "    #encoder and decoder for using my implementation of conv and other such layers:\n",
    "    def encoder_m(self, inp_im, nh, fs, strde):\n",
    "        #nh is the number of hidden layers\n",
    "        # can modify these hyperparameters, stride, final_size and filter size (3 or 5 is common) if required\n",
    "        final_size = 128\n",
    "        for i in range(nh):\n",
    "            this_name = str('conv')+str(i+1)\n",
    "            if i==0:\n",
    "                this_conv = self.conv(inp_im, this_name, fs[i], strde)\n",
    "                continue\n",
    "            this_conv = self.conv(this_conv, this_name, fs[i], strde)\n",
    "        fc_im = self.fc(this_conv, 'fc_im', final_size, non_linearity= None)\n",
    "        print(fc_im.shape)\n",
    "        return fc_im\n",
    "\n",
    "    def decoder_m(self, inp_im, nh, fs, strde, final_size, f_s):\n",
    "        fc_im = self.fc(inp_im, 'fc_deconv', final_size)\n",
    "        inp = tf.reshape(fc_im, [-1,f_s[0],f_s[1],f_s[2]]) #this makes each one of size 4 x 4 (with 4 feature maps)\n",
    "        for i in range(nh):\n",
    "            this_name = str('deconv')+str(i+1)\n",
    "            if i==0:\n",
    "                this_deconv = self.deconv(inp, this_name, fs[i], strde[i],pad='VALID')\n",
    "                continue\n",
    "            elif i==nh-1:\n",
    "                this_deconv = self.deconv(this_deconv, this_name, fs[i], strde[i],pad='VALID', non_linearity= tf.sigmoid)\n",
    "            else:\n",
    "                this_deconv = self.deconv(this_deconv, this_name, fs[i], strde[i],pad='SAME')\n",
    "        print(this_deconv.shape)\n",
    "        return this_deconv\n",
    "    \n",
    "    # cross entropy loss may be better, see that\n",
    "    def loss_v(self, orig_im, decd_im):\n",
    "        diff = (orig_im-decd_im)**2\n",
    "        return tf.div(tf.reduce_sum(diff),tf.constant(float(self.batch_size)))\n",
    "        \n",
    "    def nw_params_modify(self, bs, img_sh, learn_rt, epoch):\n",
    "        if bs is not None:\n",
    "            self.batch_size = bs\n",
    "        if img_sh is not None:\n",
    "            self.image_shape = img_sh\n",
    "        self.image_shape_batch = (self.batch_size, self.image_shape[0], self.image_shape[1], self.image_shape[2])\n",
    "        if learn_rt is not None:\n",
    "            self.learning_rate = learn_rt\n",
    "        if epoch is not None:\n",
    "            self.epoch_count = epoch\n",
    "        return\n",
    "\n",
    "    #show the original vs. decoded image\n",
    "    def show_reconstructed(self, orig, decoded_im):\n",
    "        fold_imgsave = './results/'\n",
    "        if not os.path.exists(fold_imgsave):\n",
    "              os.makedirs(fold_imgsave)\n",
    "        orig_1 = orig[:self.show_recon_num]\n",
    "        recon_1 = decoded_im[:self.show_recon_num]\n",
    "        print(recon_1)\n",
    "        img_no=1\n",
    "        for (o, r) in zip(orig_1, recon_1):\n",
    "            orig1 = np.reshape(o, (self.image_shape[0],\n",
    "                                     self.image_shape[1]))\n",
    "            recon = np.reshape(r, (self.image_shape[0],\n",
    "                                   self.image_shape[1]))\n",
    "            f, ax = plt.subplots(1,2)\n",
    "            ax[0].imshow(orig1, cmap='gray')\n",
    "            ax[1].imshow(recon, cmap='gray')\n",
    "            #plt.show()\n",
    "            plt.savefig(fold_imgsave + \"res_%d.png\" % img_no)\n",
    "            img_no+=1\n",
    "        return\n",
    "        \n",
    "    # now different types of autoencoders experimented in this exercise:\n",
    "\n",
    "    def shallow_aen(self):\n",
    "        #step-0: In shallow aen, number of hidden layers is fixed at 1\n",
    "        num_hidden_l = 1\n",
    "        f_size = 5\n",
    "        f_size_d = [5]\n",
    "        filt_e = [16]\n",
    "        filt_d = [1]\n",
    "        pad_d = ['SAME']\n",
    "        strde = 4\n",
    "        strd = [4]\n",
    "        \n",
    "        #step-1: set the parameters of the network, if needed change values here:\n",
    "        self.nw_params_modify(None,None,None,None)\n",
    "        \n",
    "        #step-1: load dataset\n",
    "        self.load_data_mnist()\n",
    "\n",
    "        #step-2: set routine for encoding the image\n",
    "        input_im = tf.placeholder(tf.float32, shape=self.image_shape_batch, name='input_im')\n",
    "        with tf.variable_scope('aen'):\n",
    "            encoded_img = self.encoder(input_im, num_hidden_l, f_size, filt_e, strde)\n",
    "            #step-3: set routine for decoding the image\n",
    "            decoded_img = self.decoder(encoded_img, num_hidden_l, f_size_d, filt_d, pad_d, strd)\n",
    "        \n",
    "        #step-4: set to calculate loss\n",
    "        loss = self.loss_v(input_im, decoded_img)\n",
    "\n",
    "        #step-5: start session and get the tf graph\n",
    "        #first, set optimizer\n",
    "        optimizer_nw = tf.train.AdamOptimizer(self.learning_rate).minimize(loss)\n",
    "        initialize = tf.global_variables_initializer()\n",
    "        this_loss = 0\n",
    "        cumul_loss = 0\n",
    "        with tf.Session() as session:\n",
    "            session.run(initialize)\n",
    "            #the data has to be trained epoch_count times in size of batch_size, so\n",
    "            #the total number of iterations in this case would be:\n",
    "            num_iter = self.epoch_count*len(self.data)\n",
    "            num_iter/= self.batch_size\n",
    "            print('Total number of iterations is, ', num_iter)\n",
    "            k=0\n",
    "            # begin iteration and training:\n",
    "            for i in range(int(num_iter)):\n",
    "                this_data = np.reshape(self.data[self.batch_size*k:self.batch_size*(k+1)],self.image_shape_batch)\n",
    "                recon_im, this_loss, this_opt = session.run([decoded_img, loss, optimizer_nw],feed_dict={input_im:this_data})\n",
    "                #print the loss every 50th iteration :\n",
    "                if i%50 == 0:\n",
    "                    print(\"Iteration \", i, \" : Loss = \", this_loss)\n",
    "                cumul_loss += this_loss\n",
    "                k+=1\n",
    "                if (self.batch_size*k)==len(self.data):\n",
    "                    k = 0\n",
    "            #step-6: display the reconstructed images in intermediate epochs\n",
    "            num_iter = len(self.test)/self.batch_size\n",
    "            k=0\n",
    "            for j in range(int(num_iter)):\n",
    "                this_test = np.reshape(self.test[self.batch_size*k:self.batch_size*(k+1)],self.image_shape_batch)\n",
    "                decoded_im = session.run(decoded_img, feed_dict={input_im:this_test})\n",
    "                if j%100 == 0:\n",
    "                    self.show_reconstructed(this_test, decoded_im)\n",
    "                k+=1\n",
    "                if (self.batch_size*k)==len(self.test):\n",
    "                    k = 0\n",
    "        return\n",
    "\n",
    "    def deep_aen(self):\n",
    "        #step-0: get the number of hidden layers:\n",
    "        num_hidden_l = 3\n",
    "        f_size = 3\n",
    "        f_size_d = [7,3,3]\n",
    "        filt_e = [16, 8, 4]\n",
    "        filt_d = [8, 16, 1]\n",
    "        pad_d = ['VALID', 'SAME', 'VALID']\n",
    "        strd = [2,2,1]\n",
    "        #step-1: set the parameters of the network, if needed change values here:\n",
    "        self.nw_params_modify(None,None,None,None)\n",
    "        \n",
    "        #step-1: load dataset\n",
    "        self.load_data_mnist()\n",
    "\n",
    "        #step-2: set routine for encoding the image\n",
    "        input_im = tf.placeholder(tf.float32, shape=self.image_shape_batch, name='input_im')\n",
    "        with tf.variable_scope('aen'):\n",
    "            encoded_img = self.encoder(input_im, num_hidden_l, f_size, filt_e, 2)\n",
    "            #step-3: set routine for decoding the image\n",
    "            decoded_img = self.decoder(encoded_img, num_hidden_l, f_size_d, filt_d, pad_d, strd)\n",
    "        \n",
    "        #step-4: set to calculate loss\n",
    "        loss = self.loss_v(input_im, decoded_img)\n",
    "\n",
    "        #step-5: start session and get the tf graph\n",
    "        #first, set optimizer\n",
    "        optimizer_nw = tf.train.AdamOptimizer(self.learning_rate).minimize(loss)\n",
    "        initialize = tf.global_variables_initializer()\n",
    "        this_loss = 0\n",
    "        cumul_loss = 0\n",
    "        with tf.Session() as session:\n",
    "            session.run(initialize)\n",
    "            #the data has to be trained epoch_count times in size of batch_size, so\n",
    "            #the total number of iterations in this case would be:\n",
    "            num_iter = self.epoch_count*len(self.data)\n",
    "            num_iter/= self.batch_size\n",
    "            print('Total number of iterations is, ', num_iter)\n",
    "            k=0\n",
    "            # begin iteration and training:\n",
    "            for i in range(int(num_iter)):\n",
    "                this_data = np.reshape(self.data[self.batch_size*k:self.batch_size*(k+1)],self.image_shape_batch)\n",
    "                recon_im, this_loss, this_opt = session.run([decoded_img, loss, optimizer_nw],feed_dict={input_im:this_data})\n",
    "                #print the loss every 50th iteration :\n",
    "                if i%50 == 0:\n",
    "                    print(\"Iteration \", i, \" : Loss = \", this_loss)\n",
    "                cumul_loss += this_loss\n",
    "                k+=1\n",
    "                if (self.batch_size*k)==len(self.data):\n",
    "                    k = 0\n",
    "            #step-6: display the reconstructed images in intermediate epochs\n",
    "            num_iter = len(self.test)/self.batch_size\n",
    "            k=0\n",
    "            for j in range(int(num_iter)):\n",
    "                this_test = np.reshape(self.test[self.batch_size*k:self.batch_size*(k+1)],self.image_shape_batch)\n",
    "                decoded_im = session.run(decoded_img, feed_dict={input_im:this_test})\n",
    "                if j%100 == 0:\n",
    "                    self.show_reconstructed(this_test, decoded_im)\n",
    "                k+=1\n",
    "                if (self.batch_size*k)==len(self.test):\n",
    "                    k = 0\n",
    "        return\n",
    "\n",
    "    def sparse_aen(self):\n",
    "        #step-0: get the number of hidden layers:\n",
    "        num_hidden_l = 3\n",
    "        f_size = 3\n",
    "        f_size_d = [7,3,3]\n",
    "        filt_e = [16, 8, 4]\n",
    "        filt_d = [8, 16, 1]\n",
    "        pad_d = ['VALID', 'SAME', 'VALID']\n",
    "        strd = [2,2,1]\n",
    "        #step-1: set the parameters of the network, if needed change values here:\n",
    "        self.nw_params_modify(None,None,None,None)\n",
    "        \n",
    "        #step-1: load dataset\n",
    "        self.load_data_mnist()\n",
    "\n",
    "        #step-2: set routine for encoding the image\n",
    "        input_im = tf.placeholder(tf.float32, shape=self.image_shape_batch, name='input_im')\n",
    "        with tf.variable_scope('aen'):\n",
    "            encoded_img = self.encoder(input_im, num_hidden_l, f_size, filt_e, 2)\n",
    "            mean_v = tf.reduce_mean(encoded_img)\n",
    "            #step-3: set routine for decoding the image\n",
    "            decoded_img = self.decoder(encoded_img, num_hidden_l, f_size_d, filt_d, pad_d, strd)\n",
    "        \n",
    "        #step-4: set to calculate loss\n",
    "        loss = self.loss_v(input_im, decoded_img)\n",
    "\n",
    "        #step-5: start session and get the tf graph\n",
    "        #first, set optimizer\n",
    "        optimizer_nw = tf.train.AdamOptimizer(self.learning_rate).minimize(loss)\n",
    "        initialize = tf.global_variables_initializer()\n",
    "        this_loss = 0\n",
    "        cumul_loss = 0\n",
    "        with tf.Session() as session:\n",
    "            session.run(initialize)\n",
    "            #the data has to be trained epoch_count times in size of batch_size, so\n",
    "            #the total number of iterations in this case would be:\n",
    "            num_iter = self.epoch_count*len(self.data)\n",
    "            num_iter/= self.batch_size\n",
    "            print('Total number of iterations is, ', num_iter)\n",
    "            k=0\n",
    "            # begin iteration and training:\n",
    "            for i in range(int(num_iter)):\n",
    "                this_data = np.reshape(self.data[self.batch_size*k:self.batch_size*(k+1)],self.image_shape_batch)\n",
    "                recon_im, this_loss, this_opt, mean_va = session.run([decoded_img, loss, optimizer_nw, mean_v],feed_dict={input_im:this_data})\n",
    "                #print the loss every 50th iteration :\n",
    "                if i%50 == 0:\n",
    "                    print(\"Iteration \", i, \" : Loss = \", this_loss, \" Encoded image mean: \", mean_va)\n",
    "                cumul_loss += this_loss\n",
    "                k+=1\n",
    "                if (self.batch_size*k)==len(self.data):\n",
    "                    k = 0\n",
    "            #step-6: display the reconstructed images in intermediate epochs\n",
    "            num_iter = len(self.test)/self.batch_size\n",
    "            k=0\n",
    "            for j in range(int(num_iter)):\n",
    "                this_test = np.reshape(self.test[self.batch_size*k:self.batch_size*(k+1)],self.image_shape_batch)\n",
    "                decoded_im = session.run(decoded_img, feed_dict={input_im:this_test})\n",
    "                if j%100 == 0:\n",
    "                    self.show_reconstructed(this_test, decoded_im)\n",
    "                k+=1\n",
    "                if (self.batch_size*k)==len(self.test):\n",
    "                    k = 0\n",
    "        return\n",
    "\n",
    "    def denoise_aen(self):\n",
    "         #step-1: set the parameters of the network, if needed change values here:\n",
    "        self.nw_params_modify(None,None,None,None)\n",
    "        \n",
    "        #step-1: load dataset\n",
    "        self.load_data_mnist()\n",
    "        \n",
    "        data_noisy = np.array(self.data).astype('float32')/255.\n",
    "        test_noisy = np.array(self.test).astype('float32')/255.\n",
    "        data_noisy = np.reshape(data_noisy,(len(data_noisy),28,28,1))\n",
    "        test_noisy = np.reshape(test_noisy,(len(test_noisy),28,28,1))\n",
    "\n",
    "        mean = 0\n",
    "        sigma = 0.002\n",
    "        noise_1 = np.random.normal(mean, sigma, size=data_noisy.shape)\n",
    "        noise_2 = np.random.normal(mean, sigma, size=test_noisy.shape)\n",
    "        data_noisy += noise_1\n",
    "        test_noisy += noise_2\n",
    "        data_noisy = np.clip(data_noisy, 0.,1.)\n",
    "        test_noisy = np.clip(test_noisy, 0.,1.)\n",
    "\n",
    "        #visualize the noisy images:\n",
    "        num_visual = 10\n",
    "        plt.figure(figsize=(32, 2))\n",
    "        for i in range(num_visual):\n",
    "            ax = plt.subplot(1, num_visual, i+1)\n",
    "            plt.imshow(data_noisy[i].reshape(28,28))\n",
    "            plt.gray()\n",
    "        plt.show()\n",
    "\n",
    "        #now design the network :\n",
    "        #trying shallow aen:\n",
    "        #step-0: In shallow aen, number of hidden layers is fixed at 1\n",
    "        num_hidden_l = 1\n",
    "        f_size = 5\n",
    "        f_size_d = [5]\n",
    "        filt_e = [64]\n",
    "        filt_d = [1]\n",
    "        pad_d = ['SAME']\n",
    "        strde = 4\n",
    "        strd = [4]\n",
    "        \n",
    "        #step-2: set routine for encoding the image\n",
    "        input_im = tf.placeholder(tf.float32, shape=self.image_shape_batch, name='input_im')\n",
    "        origg_im = tf.placeholder(tf.float32, shape=self.image_shape_batch, name='origg_im')\n",
    "        with tf.variable_scope('aen'):\n",
    "            encoded_img = self.encoder(input_im, num_hidden_l, f_size, filt_e, strde)\n",
    "            #step-3: set routine for decoding the image\n",
    "            decoded_img = self.decoder(encoded_img, num_hidden_l, f_size_d, filt_d, pad_d, strd)\n",
    "        \n",
    "        #step-4: set to calculate loss\n",
    "        loss = self.loss_v(origg_im, decoded_img)\n",
    "\n",
    "        #step-5: start session and get the tf graph\n",
    "        #first, set optimizer\n",
    "        optimizer_nw = tf.train.AdamOptimizer(self.learning_rate).minimize(loss)\n",
    "        initialize = tf.global_variables_initializer()\n",
    "        this_loss = 0\n",
    "        cumul_loss = 0\n",
    "        with tf.Session() as session:\n",
    "            session.run(initialize)\n",
    "            #the data has to be trained epoch_count times in size of batch_size, so\n",
    "            #the total number of iterations in this case would be:\n",
    "            num_iter = self.epoch_count*len(self.data)\n",
    "            num_iter/= self.batch_size\n",
    "            print('Total number of iterations is, ', num_iter)\n",
    "            k=0\n",
    "            # begin iteration and training:\n",
    "            for i in range(int(num_iter)):\n",
    "                this_data = np.reshape(data_noisy[self.batch_size*k:self.batch_size*(k+1)],self.image_shape_batch)\n",
    "                this_orig = np.reshape(self.data[self.batch_size*k:self.batch_size*(k+1)],self.image_shape_batch)\n",
    "                recon_im, this_loss, this_opt = session.run([decoded_img, loss, optimizer_nw],feed_dict={input_im:this_data, origg_im: this_orig})\n",
    "                #print the loss every 50th iteration :\n",
    "                if i%50 == 0:\n",
    "                    print(\"Iteration \", i, \" : Loss = \", this_loss)\n",
    "                cumul_loss += this_loss\n",
    "                k+=1\n",
    "                if (self.batch_size*k)==len(self.data):\n",
    "                    k = 0\n",
    "            #step-6: display the reconstructed images in intermediate epochs\n",
    "            num_iter = len(self.test)/self.batch_size\n",
    "            k=0\n",
    "            for j in range(int(num_iter)):\n",
    "                this_test = np.reshape(test_noisy[self.batch_size*k:self.batch_size*(k+1)],self.image_shape_batch)\n",
    "                decoded_im = session.run(decoded_img, feed_dict={input_im:this_test})\n",
    "                if j%100 == 0:\n",
    "                    self.show_reconstructed(this_test, decoded_im)\n",
    "                k+=1\n",
    "                if (self.batch_size*k)==len(self.test):\n",
    "                    k = 0        \n",
    "        return\n",
    "\n",
    "    def var_aen(self):\n",
    "        pass\n",
    "\n",
    "    def main(self, choice):\n",
    "        # Step 1: Try with MNIST and if it works, experiment with CIFAR-10 or some other dataset dataset\n",
    "        options = {'shallow_aen':self.shallow_aen,\n",
    "                   'deep_aen':self.deep_aen,\n",
    "                   'sparse_aen': self.sparse_aen,\n",
    "                   'denoise_aen': self.denoise_aen,\n",
    "                   'var_aen':self.var_aen,\n",
    "            }\n",
    "        options[choice]()\n",
    "        return\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # creating an instance of the AEN class\n",
    "    aen_class = AEN_analysis()\n",
    "\n",
    "    # Call to the main function\n",
    "    # Arguments to the main function is the choice of Autoencoder : available are shallow AEN, deep AEN, sparse AEN, denoising AEN, variational AEN, Stacked AEN for classification\n",
    "    tic = time.time()\n",
    "    print('Choices are : \\n 1. Shallow (1 hidden layer) AEN (shallow_aen), \\n 2. Deep AEN (deep_aen), \\n 3. Sparse Autoencoder (sparse_aen) and \\n 4. Denoising AEN(denoise_aen)')\n",
    "    choice_v = input(\"Enter the choice: \")\n",
    "    aen_class.main(choice_v)\n",
    "    toc = time.time() - tic\n",
    "    print(\"Running time: \" + str(toc))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I worked with MNIST data for the most part and as we can see from the results, this is a pretty easy dataset to work on. Other datasets take longer time for training. I tried the CIFAR-10 dataset, but that is taking quite long to train, so sharing the results of MNIST in this exercise.\n",
    "As we know, MNIST is a very popular dataset of digits with images of size (28, 28). The dataset is quite simple in the sense that the pixels are correlated and works good for testing any classification/regression/dimensionality reduction algorithms.\n",
    "\n",
    "1. Shallow AEN :\n",
    "For the shallow AEN, the network was designed this way:\n",
    " There is only one hidden layer, so \n",
    " Input --> Hidden Layer --> Output\n",
    "The values of the hyperparameters are :\n",
    "    a. Number of hidden layers = 1\n",
    "    b. Size of filter = 5 x 5\n",
    "    c. Number of filters (K) = 16\n",
    "    d. Padding type = 'SAME' (that means, zeros are padded along the image to match output dimension with input dimension)\n",
    "    e. Stride = 4 (Stride value specifies how many pixels to move when convolving with the filter)\n",
    "This screenshot shows the reduction in loss as the network is trained. The loss used throughout this exercise is the mean squared error. Binary cross entropy may be a better option and I would like to evaluate that as well.\n",
    "![Alt text](imgs/loss_red.PNG?raw=true \"loss_red\")\n",
    "\n",
    "*Analysis on Filter Size:*\n",
    "I experimented with filters of different size (going upto 7 x 7 though 7 x7 is very rarely used), so I tried 1 x 1, 3 x 3, 5 x 5 and 7 x7 filters and found that the reconstruction worked the best with filters of larger size (5x5 and 7x7)\n",
    "Here are the results with 5x5 filter size in both the encoding and decoding side\n",
    "![Alt text](imgs/res_1.png?raw=true \"res_1\")\n",
    "![Alt text](imgs/res_2.png?raw=true \"res_2\")\n",
    "![Alt text](imgs/res_4.png?raw=true \"res_4\")\n",
    "\n",
    "With 7x7 filters, the result was pretty similar\n",
    "![Alt text](imgs/res_71.png?raw=true \"res_71\")\n",
    "![Alt text](imgs/res_72.png?raw=true \"res_72\")\n",
    "![Alt text](imgs/res_74.png?raw=true \"res_74\")\n",
    "\n",
    "Now, let's look at the results from the 3 x 3 filters\n",
    "![Alt text](imgs/res_31.png?raw=true \"res_31\")\n",
    "![Alt text](imgs/res_32.png?raw=true \"res_32\")\n",
    "![Alt text](imgs/res_34.png?raw=true \"res_34\")\n",
    "\n",
    "\n",
    "And with the 1 x 1 filters,\n",
    "![Alt text](imgs/res_11.png?raw=true \"res_11\")\n",
    "![Alt text](imgs/res_12.png?raw=true \"res_12\")\n",
    "![Alt text](imgs/res_14.png?raw=true \"res_14\")\n",
    "\n",
    "We can only barely recognize the digit in this case\n",
    "\n",
    "*Analysis on # of filters (depth slice):*\n",
    "I also found that increasing the number of filters improves the loss and reconstruction. In the above hyperparameter setup K was equal to 16. This means the spatial dimensions change this way,\n",
    "28x28x1 --> 7x7x16 --> 28x28x1\n",
    "And when I change K to 64,\n",
    "28x28x1 --> 7x7x64 --> 28x28x1\n",
    "Output in this case,\n",
    "\n",
    "![Alt text](imgs/res_9.png?raw=true \"res_9\")\n",
    "![Alt text](imgs/res_10.png?raw=true \"res_10\")\n",
    "\n",
    "2. Deep AEN:\n",
    "For a deep AEN, I did not really go that deep since that would require GPU or may be very slow on a CPU. So, I set the # of hidden layers = 3. This would mean,\n",
    "Input --> Hidden Layer1 --> Hidden Layer2 ---> Hidden Layer 3 ---> Deconv Hidden1 --> Deconv Hidden2 -->Deconv Hidden3 -->Output\n",
    "\n",
    "Designing the filters in this case was a bit challenging. I had to play around with different numbers for quite sometime before I found the value of hyperparameters that converged with stability in few epochs. All of the experiments for shallow and deep AEN were iterated for 10 epochs.\n",
    "The hyperparameter values are :\n",
    "    a. Number of hidden layers = 3 (each on encoding and decoding side)\n",
    "    b. Size of filter at encoder = 3 x 3\n",
    "    c. Size of filter at decoder (layer-wise) = 7x7,3x3,3x3\n",
    "    c. Number of filters at encoder layer-wise (K) = [16,8,4]\n",
    "    d. Number of filters at decoder layer-wise (K) = [8,16,1]\n",
    "    e. Padding type = 'SAME' at encoder and for decoder (layer-wise) = ['valid', 'same', 'valid'] and here valid padding implies that there is no zero padding\n",
    "    f. Stride = 2 at encoder and [2,2,1] at decoder \n",
    "\n",
    "Usually stride is used to reduce the spatial dimension. Using the max_pool also in addition would have been a good idea.\n",
    "At the encoder side for a conv layer, the output size is determined using this formula,\n",
    "Wo = (Wi-F+2P)/S + 1\n",
    "Ho = (Hi-F+2P)/S + 1\n",
    "Where (Wo, Ho) are output shapes, (Wi, Hi) - input shape, P - padding size and S - stride size\n",
    "\n",
    "At the decoder side for a conv layer, spatial expansion happens with the stride and can be determined as,\n",
    "For same padding,\n",
    "Wo = WixSw\n",
    "Ho = HixSh\n",
    "For valid padding,\n",
    "Wo = (Wi-1)xSw + Fw\n",
    "Ho = (Hi-1)xSh + Fh\n",
    "\n",
    "With the above mentioned values of hyperparameters I achieved the following dimensionalities :\n",
    "28x28x1 --> 14x14x16 --> 7x7x8 --> 4x4x8 --> 13x13x8 --> 26x26x16 --> 28x28x1\n",
    "\n",
    "Output:\n",
    "![Alt text](imgs/loss_myfilt2.png?raw=true \"loss_myfilt2\")\n",
    "![Alt text](imgs/res_d1.png?raw=true \"res_d1\")\n",
    "![Alt text](imgs/res_d9.png?raw=true \"res_d9\")\n",
    "\n",
    "This result is from training the network with just 10 epochs. Since the network is larger, training for more epochs and also modifying the # of filters and other such hyperparameters produces better results.\n",
    "        \n",
    "3. Sparse AEN:\n",
    "For the sparse network, what I did was introduce sparsity in the activation of the nodes in the network by using regularization. The conv2D function in tensorflow has the optional argument - activity_regularizer, setting that to be equal to tf.layers.l2_regularizer(1e-05) or some scalar value enables sparsity. \n",
    "Output,\n",
    "![Alt text](imgs/res_sp4.png?raw=true \"res_sp4\")\n",
    "![Alt text](imgs/res_sp10.png?raw=true \"res_sp10\")\n",
    "As we can see there is not much difference in the reconstructed image but there is sparsity\n",
    "\n",
    "4. Denoising AEN:\n",
    "This part was really interesting. I introduced noise in the image(gaussian and salt and pepper type) in the image and trained the shallow autoencoder on the noisy images. The loss is optimized with respect to the original image and from the results below we can see that the AEN is able to recover the original images from the noisy images.\n",
    "\n",
    "![Alt text](imgs/res_de4.png?raw=true \"res_de4\")\n",
    "![Alt text](imgs/res_de8.png?raw=true \"res_de8\")\n",
    "\n",
    "I also observed that since the input is noisy, more epochs were needed to reconstruct the image. The above results are from training for 100 epochs. With 10 epochs the result is poor, as we can see below:\n",
    "![Alt text](imgs/res_de14.png?raw=true \"res_de14\")\n",
    "![Alt text](imgs/res_de7.png?raw=true \"res_de7\")\n",
    "\n",
    "It would be interesting to work with Variational Autoencoders and GAN, but ran out of time. Working on different dataset (such as the CIFAR-10) would help improve and restructure the code better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
